{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the Question Answering System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, Dense, GRU, Masking, Lambda, Bidirectional, Dropout, Reshape\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras import regularizers\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import multi_gpu_model\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "from EpisodicMemoryModule import EpisodicMemoryModule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading in Training and Dev Datasets\n",
    "It should be noted that the most recent version of the Stanford Question Answering dataset (SQuAD 2.0) includes 'impossible questions' as denoted in the dataset's '*is_impossible*' column that was not part of the dataset in earlier versions. The reason for this (according to the SQuAD website) is to encourage research into Question Answering systems that can cope with un-answerable questions by not even attempting to answer them (by returning empty string outputs or else). Given the added complexity this brings to the project, you will see in the code below that I simply exclude 'impossible questions' in this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df_all=pd.read_json(\"C:/Users/Lukas Buteliauskas/Desktop/training_data.json\").reset_index(drop=True)\n",
    "dev_df_all=pd.read_json(\"C:/Users/Lukas Buteliauskas/Desktop/validation_data.json\").reset_index(drop=True)\n",
    "\n",
    "# Dataframes consisting only of 'possible' to answer questions.\n",
    "train_df = train_df_all[train_df_all.is_impossible==False][[\"context\", \"question\", \"answer_text\",\n",
    "                                                    \"answer_start\", \"title\"]].reset_index(drop=True)\n",
    "\n",
    "dev_df = dev_df_all[dev_df_all.is_impossible==False][[\"context\", \"question\", \"answer_text\",\n",
    "                                                    \"answer_start\", \"title\"]].reset_index(drop=True)\n",
    "\n",
    "# Simple Processing/Adding answer_end\n",
    "train_df.answer_start = train_df.answer_start.astype(int)\n",
    "dev_df.answer_start = dev_df.answer_start.astype(int)\n",
    "\n",
    "contexts, questions, answers, answer_start = (train_df.context.values,\n",
    "                                              train_df.question.values, \n",
    "                                              train_df.answer_text.values,\n",
    "                                              train_df.answer_start.values)\n",
    "answer_end = np.array([answer_start[idx] + len(answers[idx]) for idx in range(len(answer_start))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Vectorization\n",
    "To be able to use words, phrases, questions or other natural language constructs in our model we require a to provide our neural network a numerical representation of our words (as these are the elemental NLP 'particles'). The simplest implementation would be to use 'one hot encoding' and define each word as a vector the size of our dictionary (the number of unique words found in our collection of documents, our corpus). However, this approach will most likely be insufficient for the purposes of a question answering system. word2vec and GloVe are 2 popular choices sophisticated options for word embeddings that also capture word similarities. I will not go into the details of either architecture other than to say that we will not be re-training the word vectors due to the insufficient size of the dataset, and we will begin with the GloVe word embeddings due to it's superior performance in most 'downstream' modelling tasks. Having said that, given the simplicity of swapping word vector representations we will also test out performance with word2vec (providing we can do so in a time-efficient manner).\n",
    "\n",
    "Info and download links for GloVe can be found at: https://nlp.stanford.edu/projects/glove/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Vector Custom Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_word_vector_dict(url_or_path):\n",
    "    \"\"\" Input: url_or_path, a URL or a local path.\n",
    "        Output: word_vector_dict, a dictionary of GloVe word vectors where words are the keys\n",
    "        and the values are the word vectors with the dimension specified in the input file.\"\"\"\n",
    "    with open(url_or_path, encoding=\"utf8\") as glove_text:\n",
    "        word_embeddings = [line.split(\" \") for line in glove_text.readlines()]\n",
    "    word_vector_dict = {element[0]:list(map(float, element[1:])) for element in word_embeddings}\n",
    "    \n",
    "    return word_vector_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up the Word Vectors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_vector_50_dict = get_word_vector_dict(\"C:/Users/Lukas Buteliauskas/Desktop/glove.6B.50d.txt\")\n",
    "vocab = np.array(word_vector_50_dict.keys()) #400k words as per the documentation.\n",
    "word_vector_100_dict = get_word_vector_dict(\"C:/Users/Lukas Buteliauskas/Desktop/glove.6B.100d.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_vector_size = 50\n",
    "hidden_units = 50\n",
    "input_h_units = int(hidden_units/2)\n",
    "num_memory_passes = 3\n",
    "regularization_val = 1e-4\n",
    "dropout = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization, Embedding, Padding Custom Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenize(string):\n",
    "    \"\"\"Takes a string (either context, question or answer) and returns the string as a list of tokens.\n",
    "    Input: string, a str object.\n",
    "    Output: a list of tokens, where each token is a substring.\"\"\"\n",
    "    tokens = [token.replace(\"``\", '\"').replace(\"''\", '\"').lower() for token in word_tokenize(string)]\n",
    "    split_tokens = []\n",
    "    \n",
    "    for token in tokens:\n",
    "        split_tokens.extend(re.split('(\\W+)', token)) # split further\n",
    "    \n",
    "    return [token for token in split_tokens if token!=\" \" and token!=\"\"]\n",
    "\n",
    "\n",
    "def get_embedding(tokens):\n",
    "    \"\"\"Takes a tokenized context, question or answer and returns its vectorized/embedded form.\n",
    "    Input: tokens, list of tokens of a string.\n",
    "    Output: embedding, a numpy array of the vectorized/embedded representation of the string.\"\"\"\n",
    "    assert word_vector_size==50 or word_vector_size==100\n",
    "    tokens = np.array(tokens)\n",
    "    embedding=[]\n",
    "    \n",
    "    if word_vector_size==50:\n",
    "        word_vector_dict=word_vector_50_dict\n",
    "    else:\n",
    "        word_vector_dict=word_vector_100_dict\n",
    "    \n",
    "    for token in tokens:\n",
    "        if token in word_vector_dict.keys(): \n",
    "            embedding.extend(word_vector_dict[token])\n",
    "        else:\n",
    "            # Words with no embedding are assigned the 'unk' token vectorization (already in GloVe)\n",
    "            embedding.extend(word_vector_dict[\"unk\"])\n",
    "    \n",
    "    return np.array(embedding)\n",
    "\n",
    "\n",
    "def get_sent_end_idx(context_tokenizations):\n",
    "    \"\"\" Get indices of tokens that are '.' (sentence end tokens). For one or many contexts.\n",
    "    Input: context_tokenizations, a list or numpy array of 1 or more tokenized contexts.\n",
    "    Output: a numpy array of indices of sentence end tokens.\"\"\"\n",
    "    return np.array([np.where(np.array(context)==\".\")[0] for context in context_tokenizations])\n",
    "\n",
    "\n",
    "def get_padded_inputs(tokenized_inputs, string_type=\"context\"):\n",
    "    \"\"\" Takes a numpy array of tokenized inputs and returns embedding and padding.\n",
    "    Input: input_array, a numpy array of question or answer tokenizations.\n",
    "    Output: (embedded_input, padded_input) a tuple of numpy arrays.\"\"\"\n",
    "    assert isinstance(tokenized_inputs[0], list)==True # Assert multiple samples\n",
    "    embedded_inputs = [get_embedding(tokenized_input) for tokenized_input in tokenized_inputs]\n",
    "    \n",
    "    if string_type==\"context\":\n",
    "        padded_input = pad_sequences(embedded_inputs, max_context_len*word_vector_size, padding=\"post\",\n",
    "                                dtype=\"float32\").reshape(len(tokenized_inputs), -1, word_vector_size)\n",
    "    elif string_type==\"question\":\n",
    "        padded_input = pad_sequences(embedded_inputs, max_question_len*word_vector_size, padding=\"post\",\n",
    "                                dtype=\"float32\").reshape(len(tokenized_inputs), -1, word_vector_size)\n",
    "    else:\n",
    "        print(\"Incorrect string_type parameter value.\")\n",
    "    \n",
    "    return padded_input\n",
    "\n",
    "\n",
    "def get_answer_span(answer_start, answer_end):\n",
    "    \"\"\" Returns one hot numpy matrices for the answer_start and answer_end indices.\n",
    "       Input: answer_start, numpy array containing the 'answer start' index in the context\n",
    "              answer_end, numpy array containing the 'answer end' index in the context\n",
    "       Output: tuple of size 2, containing the one hot embeddings of the indices for each context\"\"\"\n",
    "    y_answer_start, y_answer_end= ([] , [])\n",
    "    start_arr, end_arr = (np.zeros(shape=(output_dim,), dtype=float),\n",
    "                          np.zeros(shape=(output_dim,), dtype=float)) # Set the 0.0 arrays\n",
    "  \n",
    "    if isinstance(answer_start, np.int32) and isinstance(answer_end, np.int32): # Single sample case\n",
    "        start_arr[answer_start]=1.0\n",
    "        end_arr[answer_end]=1.0\n",
    "        y_answer_start, y_answer_end = start_arr, end_arr \n",
    "   \n",
    "    else:\n",
    "        assert len(answer_start)==len(answer_end)\n",
    "        for sample_idx in range(len(answer_start)):  # Multi sample case\n",
    "            start_arr[answer_start[sample_idx]]=1.0\n",
    "            end_arr[answer_end[sample_idx]]=1.0\n",
    "        \n",
    "            y_answer_start.append(start_arr)\n",
    "            y_answer_end.append(end_arr)\n",
    "        \n",
    "            start_arr, end_arr = (np.zeros(shape=(output_dim,), dtype=float),\n",
    "                          np.zeros(shape=(output_dim,), dtype=float)) # Reset the 0.0 arrays\n",
    "        \n",
    "    return (np.array(y_answer_start), np.array(y_answer_end))   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The nltk tokenizer generated around 110,00 unique tokens from our contexts, questions and answers in our dataset. ~31,000 of those tokens did not have pre-trained word vectorizations in the GloVe model. Some of these tokens were numbers, expressed as strings in an unfamiliar format, some of these tokens were misspelled words, some of these tokens were works in other languages, or symbols from other alphibets and so on. \n",
    "With the 'regex inspired' split in the tokenized function, we were able to reduce the number of words with no embeddings to around 16,000. To deal with the remaining words with no embeddings we assigned to them the embedding for the token *'unk'*, which by definition is the embedding for unknown words provided by GloVe. Thus any word/token that did not have an embedding got an *'unk'* embedding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up 'Trans-Batch' Variables\n",
    "All the computations needed for each batch training step will be computed later, the variables defined below have to take on values now as they are required in downstream calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\" Calculating the 'trans-batch' variables. EXECUTE THESE BEFORE ANY CHANGES TO ANYTHING\"\"\"\n",
    "tokenized_contexts = np.array([tokenize(context) for context in contexts])\n",
    "tokenized_questions = np.array([tokenize(question) for question in questions])\n",
    "tokenized_answers = np.array([tokenize(answer) for answer in answers])\n",
    "sent_end_indices = get_sent_end_idx(tokenized_contexts)\n",
    "\n",
    "# Calculating variables used within the model architecture\n",
    "max_context_len = np.max([len(context) for context in tokenized_contexts])\n",
    "max_question_len = np.max([len(question) for question in tokenized_questions])\n",
    "max_answer_len = np.max([len(answer) for answer in tokenized_answers])\n",
    "max_sent_num = np.max([len(idxs) for idxs in sent_end_indices])\n",
    "\n",
    "output_dim = np.max([len(context) for context in contexts]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the Dynamic Memory Network\n",
    "### Training Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_of_samples = len(list(train_df.context.values))\n",
    "num_of_epochs = 1\n",
    "batch_size = 128\n",
    "num_of_batches = int(num_of_samples/batch_size) # Number of iterations\n",
    "learning_rate = 0.001\n",
    "\n",
    "#num_of_batches = int(num_of_samples/batch_size) + 1 ONLY USE IF batch_size DOES NOT DIVIDE num_of_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Custom Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_facts(facts_output, sent_end_idxs):\n",
    "    \"\"\" Extracts the timesteps (facts) for each sample, then pads each tensor. Returns a 3D tensor.\n",
    "        Input: facts_output, 3D tensor of all the timesteps/samples. Shape=(num samples, max # words, 50)\n",
    "        Output: padded_fact_tensors, 3D tensor of padded fact embedding representations. \"\"\"      \n",
    "    def extract_facts(input_tuple):\n",
    "        timesteps, padded_indices = input_tuple \n",
    "        \n",
    "        num_facts = tf.count_nonzero(input_tensor=padded_indices, dtype=tf.int32, keepdims=True) \n",
    "        indices = tf.slice(input_=padded_indices, begin=tf.zeros([1,], tf.int32), size=num_facts)\n",
    " \n",
    "        facts_tensor = tf.nn.embedding_lookup(timesteps, ids=indices)\n",
    "        \n",
    "        pad = tf.zeros(shape=[max_sent_num-tf.shape(facts_tensor)[0], hidden_units], dtype=tf.float32)\n",
    "        padded_facts_tensor = K.concatenate([facts_tensor, pad], axis=0)\n",
    "        \n",
    "        return padded_facts_tensor\n",
    "    \n",
    "    input_tuple = (facts_output, sent_end_idxs)\n",
    "    padded_fact_tensors = tf.map_fn(fn=extract_facts, elems=input_tuple, dtype=tf.float32)  \n",
    "    \n",
    "    return padded_fact_tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input Module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **What it does:** The Input Module iterates over each context (paragraph of a wikipedia article) and returns embedded representations (facts) of each sentence in the context (for each sample).\n",
    "- **How it does this:** The Input Module uses a Bidirectional GRU that iterates over each word and returns the hidden state after each iteration. The GRU requires the input to be a 3D Tensor of shape (samples, timesteps, columns/features), and each sample must have the same (timesteps, columns/features) shape. However, given that our contexts are of different length (different amounts of words/timesteps), the embedded representations are padded (have 0.0s appended to each context embedding) as to meet the input requirements. As a technical side note, all embedded contexts are padded such that their length is equal to the length of the longest context in the whole sample (again, such that each individual sample has the same shape). To ensure that the GRU interprets the 0.0s as paddings, we mask the input (via the Masking layer). A Dropout Layer is added as a form of regularization. The *get_facts* method then returns the facts for each sample/context by extracting the hidden states/outputs of the GRU corresponding to 'end of sentence token' timesteps (exactly as described in the *'Ask Me Anything...'* paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "context_input = Input(shape=(max_context_len, word_vector_size), name=\"ContextInput\")\n",
    "\n",
    "sent_end_idx_input = Input(shape=(max_sent_num, ), dtype=tf.int32, name=\"IndicesInput\") \n",
    "\n",
    "context_mask = Masking(mask_value=0.0, name=\"ContextMask\")(context_input)\n",
    "\n",
    "facts_output = Bidirectional(GRU(units=input_h_units, return_sequences=True, dropout=dropout,\n",
    "                        kernel_regularizer=regularizers.l2(regularization_val),\n",
    "                        recurrent_regularizer=regularizers.l2(regularization_val)),\n",
    "                        merge_mode=\"concat\", name=\"ContextBiGRU\")(context_mask)\n",
    "\n",
    "facts_tensors = Lambda(get_facts, arguments={\"sent_end_idxs\":sent_end_idx_input},\n",
    "                                           name=\"FactTensorLambda\")(facts_output)\n",
    "facts_tensors = Reshape((max_sent_num, 2*input_h_units))(facts_tensors)\n",
    "\n",
    "#facts_mask = Masking(mask_value=0.0, name=\"FactTensorMask\")(facts_tensors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question Module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **What it does:** The Question Module (similarly to the input module) returns an embedded representation for each question. However, unlike the Input Module, the only output of the Question Module is the last hidden state of the GRU (the embedded representation). This again, is exactly the implementation defined in the beforementioned paper, but it makes sense, considering that all questions are 1 sentence long.\n",
    "- **How it does it:** Similarly to the input module (spotting a trend here) the input has to be padded and masked since not all questions are of equal length. This time a 'vanilla' unidirectional GRU is used as there is only 1 sentence/sequence, and so we wouldn't benefit from a bibirectional architecture like in the Input Module. Given that the outputs of the GRU are exactly what we want, no further processing is required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "question_input = Input(shape=(max_question_len, word_vector_size), name=\"QuestionInput\")\n",
    "\n",
    "question_mask = Masking(mask_value=0.0, name=\"QuestionMask\")(question_input)\n",
    "\n",
    "question_output = GRU(units=hidden_units, dropout=dropout,\n",
    "                      kernel_regularizer=regularizers.l2(regularization_val),\n",
    "                      recurrent_regularizer=regularizers.l2(regularization_val),\n",
    "                      name=\"QuestionGRU\")(question_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semantic Memory Module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **What it does:** The task of the Episodic Memory Module (in simplified terms) is to take the Context and Question embeddings, returned by the Input and Question modules respectively, and a return the final memory representation to the Answer Module. There are many Attention Mechanisms and various implementation details so I will cover the details of the Episodic Memory Module used in this project in the final report.\n",
    "- **How it does it:** Again, in simplified terms, this Module can be thought of to contain 2 'parts'. An *'Attention Mechanism'* and a *'Memory Update Mechanism'*. Given the 'facts' returned by the Input Module (embedded representation of each sentence in the context) and the Question Module output (which is also an embedded representation, but this time of a single sentence, the question), the Episodic Memory Module chooses which parts of the inputs (facts) to focus on through the attention mechanism. It then produces a ”memory” vector representation taking into account the question as well as the previous memory. Each iteration provides the module with newly relevant information about the input. This acts as a form of transitive reasoning, by effectively allowing the module to re-pay attention to parts of the context that it found to be relevant to answering the question. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "epm_output = EpisodicMemoryModule(units=hidden_units, memory_steps=num_memory_passes,\n",
    "                                  emb_dim=word_vector_size, batch_size=batch_size,\n",
    "                                  dropout=dropout)([facts_tensors, question_output]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Answer Module/Model Definition\n",
    "\n",
    "- **What it does:** The final module of the Dynamic Memory Network is the Answer Module. The task of the Answer Module is to produce an answer given the output of the Semantic Memory Module. Given the nature of the DMN (being modular and thus generalisable to many different types of tasks) once again there are many implementations of the Answer Module, and once again I will spare the details for the report and only give a brief outline.\n",
    "- **How it does it:** In this project we trained the network in a supervised setting. In the SQuAD dataset each answer is a span of the context meaning that the answer can be retrieved directly from the context as a continuous string. Thus the task of predicting the answer can be simplified to training the model to predict the start and end indices of the context, as this would allow us to directly extract the answer from the context. The objective/loss function is the sum of the categorical cross-entropy errors over the start/end index probability vectors (*start_idx_probs* and *end_idx_probs*.) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "ContextInput (InputLayer)       (None, 854, 50)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "ContextMask (Masking)           (None, 854, 50)      0           ContextInput[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "ContextBiGRU (Bidirectional)    (None, 854, 50)      11400       ContextMask[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "QuestionInput (InputLayer)      (None, 60, 50)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "FactTensorLambda (Lambda)       (None, None, 50)     0           ContextBiGRU[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "QuestionMask (Masking)          (None, 60, 50)       0           QuestionInput[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 42, 50)       0           FactTensorLambda[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "QuestionGRU (GRU)               (None, 50)           15150       QuestionMask[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "episodic_memory_module_1 (Episo (None, 100)          0           reshape_1[0][0]                  \n",
      "                                                                 QuestionGRU[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "StartIdxProbs (Dense)           (None, 3706)         374306      episodic_memory_module_1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "EndIdxProbs (Dense)             (None, 3706)         374306      episodic_memory_module_1[0][0]   \n",
      "==================================================================================================\n",
      "Total params: 775,162\n",
      "Trainable params: 775,162\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Defining the Answer Module\n",
    "start_idx_probs = Dense(units=output_dim, activation=\"softmax\", name=\"StartIdxProbs\",\n",
    "                        kernel_regularizer=regularizers.l2(regularization_val))(epm_output) \n",
    "\n",
    "end_idx_probs = Dense(units=output_dim, activation=\"softmax\", name=\"EndIdxProbs\",\n",
    "                      kernel_regularizer=regularizers.l2(regularization_val))(epm_output)\n",
    "\n",
    "\n",
    "# Defining the Model Architecture. 2 models, single-gpu model and multi-gpu model.\n",
    "DMN_model = Model(inputs=[context_input, sent_end_idx_input, question_input],\n",
    "                  outputs=[start_idx_probs, end_idx_probs])\n",
    "\n",
    "DMN_model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=learning_rate), \n",
    "                                                      metrics=['categorical_accuracy'])\n",
    "\n",
    "\n",
    "#multi_gpu_DMN_model = multi_gpu_model(DMN_model, gpus=2)\n",
    "\n",
    "##multi_gpu_DMN_model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=learning_rate), \n",
    "                                                      #metrics=['categorical_accuracy'])\n",
    "\n",
    "print(DMN_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the Dynamic Memory Network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_answer_start, y_answer_end = (get_answer_span(answer_start[0:batch_size], answer_end[0:batch_size]))\n",
    "padded_contexts = get_padded_inputs(tokenized_contexts[0:batch_size], string_type=\"context\")\n",
    "padded_questions = get_padded_inputs(tokenized_questions[0:batch_size], string_type=\"question\")\n",
    "padded_sent_end_indices = pad_sequences(sent_end_indices[0:batch_size], max_sent_num,\n",
    "                                                                    padding=\"post\", dtype=\"int32\")\n",
    "\n",
    "#history = DMN_model.fit(x=[padded_contexts, padded_sent_end_indices, padded_questions],\n",
    " #                       y=[y_answer_start, y_answer_end],\n",
    "  #                      batch_size=batch_size, validation_split=0.1)\n",
    "\n",
    "#history_2 = multi_gpu_DMN_model.fit(x=[padded_contexts, padded_sent_end_indices, padded_questions],\n",
    "                        #y=[y_answer_start, y_answer_end],\n",
    "                        #batch_size=batch_size, validation_split=0.1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/1     Batch 1/678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lukas Buteliauskas\\Anaconda3_\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py:100: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 115s 1s/step - loss: 16.5209 - StartIdxProbs_loss: 8.2211 - EndIdxProbs_loss: 8.2313 - StartIdxProbs_categorical_accuracy: 0.0087 - EndIdxProbs_categorical_accuracy: 0.0000e+00 - val_loss: 16.5288 - val_StartIdxProbs_loss: 8.2374 - val_EndIdxProbs_loss: 8.2235 - val_StartIdxProbs_categorical_accuracy: 0.0000e+00 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 1/1     Batch 2/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 2s 16ms/step - loss: 16.5053 - StartIdxProbs_loss: 8.2198 - EndIdxProbs_loss: 8.2176 - StartIdxProbs_categorical_accuracy: 0.0000e+00 - EndIdxProbs_categorical_accuracy: 0.0000e+00 - val_loss: 16.5072 - val_StartIdxProbs_loss: 8.2292 - val_EndIdxProbs_loss: 8.2106 - val_StartIdxProbs_categorical_accuracy: 0.0000e+00 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 1/1     Batch 3/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 2s 21ms/step - loss: 16.4947 - StartIdxProbs_loss: 8.2154 - EndIdxProbs_loss: 8.2118 - StartIdxProbs_categorical_accuracy: 0.0000e+00 - EndIdxProbs_categorical_accuracy: 0.0000e+00 - val_loss: 16.5118 - val_StartIdxProbs_loss: 8.2316 - val_EndIdxProbs_loss: 8.2132 - val_StartIdxProbs_categorical_accuracy: 0.0000e+00 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 1/1     Batch 4/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 2s 20ms/step - loss: 16.4695 - StartIdxProbs_loss: 8.1957 - EndIdxProbs_loss: 8.2068 - StartIdxProbs_categorical_accuracy: 0.0000e+00 - EndIdxProbs_categorical_accuracy: 0.0000e+00 - val_loss: 16.4330 - val_StartIdxProbs_loss: 8.1649 - val_EndIdxProbs_loss: 8.2015 - val_StartIdxProbs_categorical_accuracy: 0.0000e+00 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 1/1     Batch 5/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 2s 20ms/step - loss: 16.4501 - StartIdxProbs_loss: 8.1791 - EndIdxProbs_loss: 8.2044 - StartIdxProbs_categorical_accuracy: 0.0000e+00 - EndIdxProbs_categorical_accuracy: 0.0000e+00 - val_loss: 16.4661 - val_StartIdxProbs_loss: 8.1753 - val_EndIdxProbs_loss: 8.2244 - val_StartIdxProbs_categorical_accuracy: 0.0000e+00 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 1/1     Batch 6/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 2s 21ms/step - loss: 16.4333 - StartIdxProbs_loss: 8.1777 - EndIdxProbs_loss: 8.1893 - StartIdxProbs_categorical_accuracy: 0.0087 - EndIdxProbs_categorical_accuracy: 0.0000e+00 - val_loss: 16.3574 - val_StartIdxProbs_loss: 8.1130 - val_EndIdxProbs_loss: 8.1782 - val_StartIdxProbs_categorical_accuracy: 0.0000e+00 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 1/1     Batch 7/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 2s 21ms/step - loss: 16.4121 - StartIdxProbs_loss: 8.1671 - EndIdxProbs_loss: 8.1788 - StartIdxProbs_categorical_accuracy: 0.0087 - EndIdxProbs_categorical_accuracy: 0.0000e+00 - val_loss: 16.4433 - val_StartIdxProbs_loss: 8.1746 - val_EndIdxProbs_loss: 8.2026 - val_StartIdxProbs_categorical_accuracy: 0.0000e+00 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 1/1     Batch 8/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 2s 20ms/step - loss: 16.4018 - StartIdxProbs_loss: 8.1536 - EndIdxProbs_loss: 8.1821 - StartIdxProbs_categorical_accuracy: 0.0000e+00 - EndIdxProbs_categorical_accuracy: 0.0000e+00 - val_loss: 16.3721 - val_StartIdxProbs_loss: 8.1470 - val_EndIdxProbs_loss: 8.1590 - val_StartIdxProbs_categorical_accuracy: 0.0000e+00 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 1/1     Batch 9/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 3s 26ms/step - loss: 16.3584 - StartIdxProbs_loss: 8.1433 - EndIdxProbs_loss: 8.1490 - StartIdxProbs_categorical_accuracy: 0.0000e+00 - EndIdxProbs_categorical_accuracy: 0.0000e+00 - val_loss: 16.3231 - val_StartIdxProbs_loss: 8.1304 - val_EndIdxProbs_loss: 8.1264 - val_StartIdxProbs_categorical_accuracy: 0.0000e+00 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 1/1     Batch 10/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 2s 19ms/step - loss: 16.2859 - StartIdxProbs_loss: 8.1032 - EndIdxProbs_loss: 8.1164 - StartIdxProbs_categorical_accuracy: 0.0000e+00 - EndIdxProbs_categorical_accuracy: 0.0000e+00 - val_loss: 16.2957 - val_StartIdxProbs_loss: 8.0893 - val_EndIdxProbs_loss: 8.1398 - val_StartIdxProbs_categorical_accuracy: 0.0000e+00 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 1/1     Batch 11/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 2s 19ms/step - loss: 16.2687 - StartIdxProbs_loss: 8.0982 - EndIdxProbs_loss: 8.1040 - StartIdxProbs_categorical_accuracy: 0.0087 - EndIdxProbs_categorical_accuracy: 0.0000e+00 - val_loss: 16.3103 - val_StartIdxProbs_loss: 8.1030 - val_EndIdxProbs_loss: 8.1404 - val_StartIdxProbs_categorical_accuracy: 0.0769 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 1/1     Batch 12/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 2s 18ms/step - loss: 16.2478 - StartIdxProbs_loss: 8.0650 - EndIdxProbs_loss: 8.1159 - StartIdxProbs_categorical_accuracy: 0.0000e+00 - EndIdxProbs_categorical_accuracy: 0.0087 - val_loss: 16.2799 - val_StartIdxProbs_loss: 8.1176 - val_EndIdxProbs_loss: 8.0950 - val_StartIdxProbs_categorical_accuracy: 0.0000e+00 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 1/1     Batch 13/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 2s 16ms/step - loss: 16.1871 - StartIdxProbs_loss: 8.0467 - EndIdxProbs_loss: 8.0730 - StartIdxProbs_categorical_accuracy: 0.0087 - EndIdxProbs_categorical_accuracy: 0.0000e+00 - val_loss: 16.1641 - val_StartIdxProbs_loss: 8.0423 - val_EndIdxProbs_loss: 8.0538 - val_StartIdxProbs_categorical_accuracy: 0.0000e+00 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 1/1     Batch 14/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 2s 16ms/step - loss: 16.1396 - StartIdxProbs_loss: 8.0136 - EndIdxProbs_loss: 8.0580 - StartIdxProbs_categorical_accuracy: 0.0000e+00 - EndIdxProbs_categorical_accuracy: 0.0000e+00 - val_loss: 16.0204 - val_StartIdxProbs_loss: 7.9351 - val_EndIdxProbs_loss: 8.0166 - val_StartIdxProbs_categorical_accuracy: 0.0000e+00 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 1/1     Batch 15/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 2s 15ms/step - loss: 16.1088 - StartIdxProbs_loss: 8.0091 - EndIdxProbs_loss: 8.0310 - StartIdxProbs_categorical_accuracy: 0.0174 - EndIdxProbs_categorical_accuracy: 0.0000e+00 - val_loss: 16.0592 - val_StartIdxProbs_loss: 7.9830 - val_EndIdxProbs_loss: 8.0067 - val_StartIdxProbs_categorical_accuracy: 0.0000e+00 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 1/1     Batch 16/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 2s 15ms/step - loss: 16.0557 - StartIdxProbs_loss: 7.9948 - EndIdxProbs_loss: 7.9913 - StartIdxProbs_categorical_accuracy: 0.0087 - EndIdxProbs_categorical_accuracy: 0.0000e+00 - val_loss: 15.8089 - val_StartIdxProbs_loss: 7.8843 - val_EndIdxProbs_loss: 7.8542 - val_StartIdxProbs_categorical_accuracy: 0.0769 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 1/1     Batch 17/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 2s 17ms/step - loss: 16.0483 - StartIdxProbs_loss: 7.9786 - EndIdxProbs_loss: 7.9993 - StartIdxProbs_categorical_accuracy: 0.0174 - EndIdxProbs_categorical_accuracy: 0.0000e+00 - val_loss: 16.0677 - val_StartIdxProbs_loss: 8.0260 - val_EndIdxProbs_loss: 7.9702 - val_StartIdxProbs_categorical_accuracy: 0.0000e+00 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/1     Batch 18/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 2s 16ms/step - loss: 15.9367 - StartIdxProbs_loss: 7.9188 - EndIdxProbs_loss: 7.9463 - StartIdxProbs_categorical_accuracy: 0.0348 - EndIdxProbs_categorical_accuracy: 0.0000e+00 - val_loss: 15.8475 - val_StartIdxProbs_loss: 7.8335 - val_EndIdxProbs_loss: 7.9413 - val_StartIdxProbs_categorical_accuracy: 0.0000e+00 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 1/1     Batch 19/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 2s 15ms/step - loss: 15.8770 - StartIdxProbs_loss: 7.9071 - EndIdxProbs_loss: 7.8973 - StartIdxProbs_categorical_accuracy: 0.0000e+00 - EndIdxProbs_categorical_accuracy: 0.0000e+00 - val_loss: 15.8763 - val_StartIdxProbs_loss: 7.9015 - val_EndIdxProbs_loss: 7.9008 - val_StartIdxProbs_categorical_accuracy: 0.0000e+00 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 1/1     Batch 20/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 2s 15ms/step - loss: 15.9018 - StartIdxProbs_loss: 7.9121 - EndIdxProbs_loss: 7.9157 - StartIdxProbs_categorical_accuracy: 0.0000e+00 - EndIdxProbs_categorical_accuracy: 0.0000e+00 - val_loss: 15.9041 - val_StartIdxProbs_loss: 7.9030 - val_EndIdxProbs_loss: 7.9256 - val_StartIdxProbs_categorical_accuracy: 0.0000e+00 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 1/1     Batch 21/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 2s 15ms/step - loss: 15.9007 - StartIdxProbs_loss: 7.9057 - EndIdxProbs_loss: 7.9195 - StartIdxProbs_categorical_accuracy: 0.0000e+00 - EndIdxProbs_categorical_accuracy: 0.0000e+00 - val_loss: 15.5450 - val_StartIdxProbs_loss: 7.6025 - val_EndIdxProbs_loss: 7.8655 - val_StartIdxProbs_categorical_accuracy: 0.0769 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 1/1     Batch 22/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 2s 16ms/step - loss: 15.6897 - StartIdxProbs_loss: 7.7931 - EndIdxProbs_loss: 7.8196 - StartIdxProbs_categorical_accuracy: 0.0435 - EndIdxProbs_categorical_accuracy: 0.0087 - val_loss: 15.6701 - val_StartIdxProbs_loss: 7.7499 - val_EndIdxProbs_loss: 7.8415 - val_StartIdxProbs_categorical_accuracy: 0.0000e+00 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 1/1     Batch 23/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 2s 19ms/step - loss: 15.6781 - StartIdxProbs_loss: 7.7889 - EndIdxProbs_loss: 7.8106 - StartIdxProbs_categorical_accuracy: 0.0087 - EndIdxProbs_categorical_accuracy: 0.0000e+00 - val_loss: 15.6700 - val_StartIdxProbs_loss: 7.8164 - val_EndIdxProbs_loss: 7.7731 - val_StartIdxProbs_categorical_accuracy: 0.0000e+00 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 1/1     Batch 24/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 2s 16ms/step - loss: 15.4854 - StartIdxProbs_loss: 7.6812 - EndIdxProbs_loss: 7.7236 - StartIdxProbs_categorical_accuracy: 0.0087 - EndIdxProbs_categorical_accuracy: 0.0000e+00 - val_loss: 15.6343 - val_StartIdxProbs_loss: 7.7114 - val_EndIdxProbs_loss: 7.8404 - val_StartIdxProbs_categorical_accuracy: 0.0000e+00 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 1/1     Batch 25/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 2s 16ms/step - loss: 15.4537 - StartIdxProbs_loss: 7.6778 - EndIdxProbs_loss: 7.6935 - StartIdxProbs_categorical_accuracy: 0.0174 - EndIdxProbs_categorical_accuracy: 0.0000e+00 - val_loss: 15.4414 - val_StartIdxProbs_loss: 7.8450 - val_EndIdxProbs_loss: 7.5118 - val_StartIdxProbs_categorical_accuracy: 0.0000e+00 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 1/1     Batch 26/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 2s 15ms/step - loss: 15.3017 - StartIdxProbs_loss: 7.5461 - EndIdxProbs_loss: 7.6711 - StartIdxProbs_categorical_accuracy: 0.0348 - EndIdxProbs_categorical_accuracy: 0.0000e+00 - val_loss: 15.1690 - val_StartIdxProbs_loss: 7.5446 - val_EndIdxProbs_loss: 7.5377 - val_StartIdxProbs_categorical_accuracy: 0.0000e+00 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 1/1     Batch 27/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 2s 16ms/step - loss: 15.2146 - StartIdxProbs_loss: 7.5399 - EndIdxProbs_loss: 7.5880 - StartIdxProbs_categorical_accuracy: 0.0261 - EndIdxProbs_categorical_accuracy: 0.0000e+00 - val_loss: 14.9732 - val_StartIdxProbs_loss: 7.5997 - val_EndIdxProbs_loss: 7.2845 - val_StartIdxProbs_categorical_accuracy: 0.0000e+00 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 1/1     Batch 28/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 2s 16ms/step - loss: 15.1501 - StartIdxProbs_loss: 7.5135 - EndIdxProbs_loss: 7.5475 - StartIdxProbs_categorical_accuracy: 0.0348 - EndIdxProbs_categorical_accuracy: 0.0000e+00 - val_loss: 15.4497 - val_StartIdxProbs_loss: 7.6646 - val_EndIdxProbs_loss: 7.6937 - val_StartIdxProbs_categorical_accuracy: 0.0000e+00 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 1/1     Batch 29/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 2s 15ms/step - loss: 15.0676 - StartIdxProbs_loss: 7.4786 - EndIdxProbs_loss: 7.4976 - StartIdxProbs_categorical_accuracy: 0.0174 - EndIdxProbs_categorical_accuracy: 0.0000e+00 - val_loss: 14.4717 - val_StartIdxProbs_loss: 7.1065 - val_EndIdxProbs_loss: 7.2712 - val_StartIdxProbs_categorical_accuracy: 0.1538 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 1/1     Batch 30/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 2s 15ms/step - loss: 15.0630 - StartIdxProbs_loss: 7.4465 - EndIdxProbs_loss: 7.5227 - StartIdxProbs_categorical_accuracy: 0.0435 - EndIdxProbs_categorical_accuracy: 0.0000e+00 - val_loss: 14.8606 - val_StartIdxProbs_loss: 7.3689 - val_EndIdxProbs_loss: 7.3951 - val_StartIdxProbs_categorical_accuracy: 0.0000e+00 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 1/1     Batch 31/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 2s 16ms/step - loss: 14.9097 - StartIdxProbs_loss: 7.4416 - EndIdxProbs_loss: 7.3715 - StartIdxProbs_categorical_accuracy: 0.0087 - EndIdxProbs_categorical_accuracy: 0.0000e+00 - val_loss: 14.8225 - val_StartIdxProbs_loss: 7.4855 - val_EndIdxProbs_loss: 7.2377 - val_StartIdxProbs_categorical_accuracy: 0.0000e+00 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 1/1     Batch 32/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 2s 16ms/step - loss: 14.7000 - StartIdxProbs_loss: 7.2721 - EndIdxProbs_loss: 7.3286 - StartIdxProbs_categorical_accuracy: 0.0000e+00 - EndIdxProbs_categorical_accuracy: 0.0000e+00 - val_loss: 14.6947 - val_StartIdxProbs_loss: 7.1326 - val_EndIdxProbs_loss: 7.4601 - val_StartIdxProbs_categorical_accuracy: 0.0000e+00 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 1/1     Batch 33/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 2s 16ms/step - loss: 14.8568 - StartIdxProbs_loss: 7.3535 - EndIdxProbs_loss: 7.4013 - StartIdxProbs_categorical_accuracy: 0.0261 - EndIdxProbs_categorical_accuracy: 0.0000e+00 - val_loss: 14.2560 - val_StartIdxProbs_loss: 7.1844 - val_EndIdxProbs_loss: 6.9666 - val_StartIdxProbs_categorical_accuracy: 0.0000e+00 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 1/1     Batch 34/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 2s 21ms/step - loss: 14.3037 - StartIdxProbs_loss: 7.1027 - EndIdxProbs_loss: 7.0960 - StartIdxProbs_categorical_accuracy: 0.0000e+00 - EndIdxProbs_categorical_accuracy: 0.0087 - val_loss: 13.9901 - val_StartIdxProbs_loss: 6.9360 - val_EndIdxProbs_loss: 6.9462 - val_StartIdxProbs_categorical_accuracy: 0.0000e+00 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/1     Batch 35/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 3s 22ms/step - loss: 14.3729 - StartIdxProbs_loss: 7.1007 - EndIdxProbs_loss: 7.1643 - StartIdxProbs_categorical_accuracy: 0.0174 - EndIdxProbs_categorical_accuracy: 0.0000e+00 - val_loss: 14.4579 - val_StartIdxProbs_loss: 7.2697 - val_EndIdxProbs_loss: 7.0773 - val_StartIdxProbs_categorical_accuracy: 0.0000e+00 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 1/1     Batch 36/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 2s 22ms/step - loss: 14.5208 - StartIdxProbs_loss: 7.1357 - EndIdxProbs_loss: 7.2742 - StartIdxProbs_categorical_accuracy: 0.0435 - EndIdxProbs_categorical_accuracy: 0.0000e+00 - val_loss: 14.4224 - val_StartIdxProbs_loss: 7.2341 - val_EndIdxProbs_loss: 7.0743 - val_StartIdxProbs_categorical_accuracy: 0.0000e+00 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 1/1     Batch 37/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 3s 23ms/step - loss: 14.5835 - StartIdxProbs_loss: 7.1868 - EndIdxProbs_loss: 7.2828 - StartIdxProbs_categorical_accuracy: 0.0261 - EndIdxProbs_categorical_accuracy: 0.0000e+00 - val_loss: 14.6571 - val_StartIdxProbs_loss: 7.2621 - val_EndIdxProbs_loss: 7.2780 - val_StartIdxProbs_categorical_accuracy: 0.0769 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 1/1     Batch 38/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 2s 21ms/step - loss: 14.3715 - StartIdxProbs_loss: 7.1293 - EndIdxProbs_loss: 7.1252 - StartIdxProbs_categorical_accuracy: 0.0174 - EndIdxProbs_categorical_accuracy: 0.0000e+00 - val_loss: 14.6103 - val_StartIdxProbs_loss: 7.1744 - val_EndIdxProbs_loss: 7.3158 - val_StartIdxProbs_categorical_accuracy: 0.0000e+00 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 1/1     Batch 39/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 3s 24ms/step - loss: 14.8460 - StartIdxProbs_loss: 7.3363 - EndIdxProbs_loss: 7.3896 - StartIdxProbs_categorical_accuracy: 0.0000e+00 - EndIdxProbs_categorical_accuracy: 0.0000e+00 - val_loss: 14.3759 - val_StartIdxProbs_loss: 7.1276 - val_EndIdxProbs_loss: 7.1251 - val_StartIdxProbs_categorical_accuracy: 0.0000e+00 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 1/1     Batch 40/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 3s 22ms/step - loss: 14.2286 - StartIdxProbs_loss: 7.0638 - EndIdxProbs_loss: 7.0416 - StartIdxProbs_categorical_accuracy: 0.0000e+00 - EndIdxProbs_categorical_accuracy: 0.0174 - val_loss: 13.7198 - val_StartIdxProbs_loss: 6.9134 - val_EndIdxProbs_loss: 6.6802 - val_StartIdxProbs_categorical_accuracy: 0.0000e+00 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 1/1     Batch 41/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 2s 19ms/step - loss: 14.0812 - StartIdxProbs_loss: 6.9604 - EndIdxProbs_loss: 6.9947 - StartIdxProbs_categorical_accuracy: 0.0087 - EndIdxProbs_categorical_accuracy: 0.0000e+00 - val_loss: 13.8765 - val_StartIdxProbs_loss: 6.9301 - val_EndIdxProbs_loss: 6.8172 - val_StartIdxProbs_categorical_accuracy: 0.0000e+00 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 1/1     Batch 42/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 2s 20ms/step - loss: 14.3731 - StartIdxProbs_loss: 7.0897 - EndIdxProbs_loss: 7.1542 - StartIdxProbs_categorical_accuracy: 0.0000e+00 - EndIdxProbs_categorical_accuracy: 0.0000e+00 - val_loss: 13.7884 - val_StartIdxProbs_loss: 6.9377 - val_EndIdxProbs_loss: 6.7186 - val_StartIdxProbs_categorical_accuracy: 0.0000e+00 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 1/1     Batch 43/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 2s 15ms/step - loss: 14.2295 - StartIdxProbs_loss: 7.1173 - EndIdxProbs_loss: 6.9800 - StartIdxProbs_categorical_accuracy: 0.0000e+00 - EndIdxProbs_categorical_accuracy: 0.0000e+00 - val_loss: 14.1015 - val_StartIdxProbs_loss: 6.8548 - val_EndIdxProbs_loss: 7.1117 - val_StartIdxProbs_categorical_accuracy: 0.0000e+00 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 1/1     Batch 44/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 2s 18ms/step - loss: 14.1867 - StartIdxProbs_loss: 6.9465 - EndIdxProbs_loss: 7.1052 - StartIdxProbs_categorical_accuracy: 0.0174 - EndIdxProbs_categorical_accuracy: 0.0087 - val_loss: 13.7869 - val_StartIdxProbs_loss: 6.7213 - val_EndIdxProbs_loss: 6.9277 - val_StartIdxProbs_categorical_accuracy: 0.0000e+00 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 1/1     Batch 45/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 2s 22ms/step - loss: 13.9044 - StartIdxProbs_loss: 6.8282 - EndIdxProbs_loss: 6.9384 - StartIdxProbs_categorical_accuracy: 0.0174 - EndIdxProbs_categorical_accuracy: 0.0000e+00 - val_loss: 14.0985 - val_StartIdxProbs_loss: 6.8709 - val_EndIdxProbs_loss: 7.0870 - val_StartIdxProbs_categorical_accuracy: 0.0000e+00 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 1/1     Batch 46/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 2s 19ms/step - loss: 14.2760 - StartIdxProbs_loss: 7.0448 - EndIdxProbs_loss: 7.0906 - StartIdxProbs_categorical_accuracy: 0.0174 - EndIdxProbs_categorical_accuracy: 0.0000e+00 - val_loss: 15.8354 - val_StartIdxProbs_loss: 7.8640 - val_EndIdxProbs_loss: 7.8282 - val_StartIdxProbs_categorical_accuracy: 0.0000e+00 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 1/1     Batch 47/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 2s 16ms/step - loss: 14.0025 - StartIdxProbs_loss: 6.8588 - EndIdxProbs_loss: 7.0004 - StartIdxProbs_categorical_accuracy: 0.0087 - EndIdxProbs_categorical_accuracy: 0.0000e+00 - val_loss: 15.7151 - val_StartIdxProbs_loss: 7.7868 - val_EndIdxProbs_loss: 7.7825 - val_StartIdxProbs_categorical_accuracy: 0.0000e+00 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 1/1     Batch 48/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 2s 16ms/step - loss: 13.8039 - StartIdxProbs_loss: 6.8650 - EndIdxProbs_loss: 6.7931 - StartIdxProbs_categorical_accuracy: 0.0087 - EndIdxProbs_categorical_accuracy: 0.0000e+00 - val_loss: 14.0183 - val_StartIdxProbs_loss: 7.0320 - val_EndIdxProbs_loss: 6.8379 - val_StartIdxProbs_categorical_accuracy: 0.0000e+00 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 1/1     Batch 49/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 2s 16ms/step - loss: 13.7714 - StartIdxProbs_loss: 6.7281 - EndIdxProbs_loss: 6.8949 - StartIdxProbs_categorical_accuracy: 0.0000e+00 - EndIdxProbs_categorical_accuracy: 0.0000e+00 - val_loss: 13.6190 - val_StartIdxProbs_loss: 6.7956 - val_EndIdxProbs_loss: 6.6727 - val_StartIdxProbs_categorical_accuracy: 0.0000e+00 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 1/1     Batch 50/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 2s 16ms/step - loss: 14.1403 - StartIdxProbs_loss: 6.9413 - EndIdxProbs_loss: 7.0483 - StartIdxProbs_categorical_accuracy: 0.0174 - EndIdxProbs_categorical_accuracy: 0.0000e+00 - val_loss: 13.4817 - val_StartIdxProbs_loss: 6.5473 - val_EndIdxProbs_loss: 6.7814 - val_StartIdxProbs_categorical_accuracy: 0.1538 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 1/1     Batch 51/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 2s 19ms/step - loss: 14.3698 - StartIdxProbs_loss: 7.0884 - EndIdxProbs_loss: 7.1284 - StartIdxProbs_categorical_accuracy: 0.0261 - EndIdxProbs_categorical_accuracy: 0.0087 - val_loss: 16.2522 - val_StartIdxProbs_loss: 7.8478 - val_EndIdxProbs_loss: 8.2491 - val_StartIdxProbs_categorical_accuracy: 0.0000e+00 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/1     Batch 52/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 2s 17ms/step - loss: 14.1846 - StartIdxProbs_loss: 6.9824 - EndIdxProbs_loss: 7.0470 - StartIdxProbs_categorical_accuracy: 0.0087 - EndIdxProbs_categorical_accuracy: 0.0000e+00 - val_loss: 14.0824 - val_StartIdxProbs_loss: 6.9766 - val_EndIdxProbs_loss: 6.9485 - val_StartIdxProbs_categorical_accuracy: 0.0000e+00 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 1/1     Batch 53/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 2s 15ms/step - loss: 13.9343 - StartIdxProbs_loss: 6.8405 - EndIdxProbs_loss: 6.9366 - StartIdxProbs_categorical_accuracy: 0.0087 - EndIdxProbs_categorical_accuracy: 0.0174 - val_loss: 14.1125 - val_StartIdxProbs_loss: 6.9366 - val_EndIdxProbs_loss: 7.0166 - val_StartIdxProbs_categorical_accuracy: 0.0769 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 1/1     Batch 54/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 2s 15ms/step - loss: 14.2589 - StartIdxProbs_loss: 7.0635 - EndIdxProbs_loss: 7.0360 - StartIdxProbs_categorical_accuracy: 0.0087 - EndIdxProbs_categorical_accuracy: 0.0000e+00 - val_loss: 13.4619 - val_StartIdxProbs_loss: 6.5301 - val_EndIdxProbs_loss: 6.7707 - val_StartIdxProbs_categorical_accuracy: 0.0000e+00 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 1/1     Batch 55/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 2s 16ms/step - loss: 14.0644 - StartIdxProbs_loss: 6.9405 - EndIdxProbs_loss: 6.9628 - StartIdxProbs_categorical_accuracy: 0.0348 - EndIdxProbs_categorical_accuracy: 0.0000e+00 - val_loss: 15.2061 - val_StartIdxProbs_loss: 7.7534 - val_EndIdxProbs_loss: 7.2899 - val_StartIdxProbs_categorical_accuracy: 0.0000e+00 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 1/1     Batch 56/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 2s 16ms/step - loss: 14.0346 - StartIdxProbs_loss: 7.0227 - EndIdxProbs_loss: 6.8489 - StartIdxProbs_categorical_accuracy: 0.0000e+00 - EndIdxProbs_categorical_accuracy: 0.0174 - val_loss: 14.0900 - val_StartIdxProbs_loss: 6.8730 - val_EndIdxProbs_loss: 7.0525 - val_StartIdxProbs_categorical_accuracy: 0.0000e+00 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 1/1     Batch 57/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 2s 15ms/step - loss: 14.0817 - StartIdxProbs_loss: 6.9327 - EndIdxProbs_loss: 6.9845 - StartIdxProbs_categorical_accuracy: 0.0000e+00 - EndIdxProbs_categorical_accuracy: 0.0000e+00 - val_loss: 13.9292 - val_StartIdxProbs_loss: 7.0498 - val_EndIdxProbs_loss: 6.7133 - val_StartIdxProbs_categorical_accuracy: 0.0000e+00 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 1/1     Batch 58/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 2s 15ms/step - loss: 13.7853 - StartIdxProbs_loss: 6.7816 - EndIdxProbs_loss: 6.8376 - StartIdxProbs_categorical_accuracy: 0.0261 - EndIdxProbs_categorical_accuracy: 0.0087 - val_loss: 13.9687 - val_StartIdxProbs_loss: 6.9530 - val_EndIdxProbs_loss: 6.8481 - val_StartIdxProbs_categorical_accuracy: 0.0000e+00 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 1/1     Batch 59/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 2s 16ms/step - loss: 14.0096 - StartIdxProbs_loss: 6.8343 - EndIdxProbs_loss: 7.0077 - StartIdxProbs_categorical_accuracy: 0.0087 - EndIdxProbs_categorical_accuracy: 0.0000e+00 - val_loss: 13.7422 - val_StartIdxProbs_loss: 6.6110 - val_EndIdxProbs_loss: 6.9622 - val_StartIdxProbs_categorical_accuracy: 0.0769 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 1/1     Batch 60/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 2s 16ms/step - loss: 13.8573 - StartIdxProbs_loss: 6.8161 - EndIdxProbs_loss: 6.8722 - StartIdxProbs_categorical_accuracy: 0.0261 - EndIdxProbs_categorical_accuracy: 0.0087 - val_loss: 13.9432 - val_StartIdxProbs_loss: 6.9951 - val_EndIdxProbs_loss: 6.7779 - val_StartIdxProbs_categorical_accuracy: 0.0000e+00 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 1/1     Batch 61/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 2s 16ms/step - loss: 14.3366 - StartIdxProbs_loss: 7.0218 - EndIdxProbs_loss: 7.1445 - StartIdxProbs_categorical_accuracy: 0.0087 - EndIdxProbs_categorical_accuracy: 0.0000e+00 - val_loss: 14.3914 - val_StartIdxProbs_loss: 7.2231 - val_EndIdxProbs_loss: 6.9969 - val_StartIdxProbs_categorical_accuracy: 0.0769 - val_EndIdxProbs_categorical_accuracy: 0.0769\n",
      "\n",
      "Epoch 1/1     Batch 62/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 2s 16ms/step - loss: 14.5915 - StartIdxProbs_loss: 7.2395 - EndIdxProbs_loss: 7.1806 - StartIdxProbs_categorical_accuracy: 0.0348 - EndIdxProbs_categorical_accuracy: 0.0000e+00 - val_loss: 13.9467 - val_StartIdxProbs_loss: 6.9865 - val_EndIdxProbs_loss: 6.7877 - val_StartIdxProbs_categorical_accuracy: 0.0000e+00 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 1/1     Batch 63/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 2s 16ms/step - loss: 13.9493 - StartIdxProbs_loss: 6.8479 - EndIdxProbs_loss: 6.9288 - StartIdxProbs_categorical_accuracy: 0.0609 - EndIdxProbs_categorical_accuracy: 0.0087 - val_loss: 14.1259 - val_StartIdxProbs_loss: 6.9954 - val_EndIdxProbs_loss: 6.9569 - val_StartIdxProbs_categorical_accuracy: 0.0769 - val_EndIdxProbs_categorical_accuracy: 0.0769\n",
      "\n",
      "Epoch 1/1     Batch 64/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 2s 16ms/step - loss: 14.0586 - StartIdxProbs_loss: 6.7876 - EndIdxProbs_loss: 7.0974 - StartIdxProbs_categorical_accuracy: 0.1043 - EndIdxProbs_categorical_accuracy: 0.0087 - val_loss: 13.7855 - val_StartIdxProbs_loss: 6.7360 - val_EndIdxProbs_loss: 6.8750 - val_StartIdxProbs_categorical_accuracy: 0.0000e+00 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 1/1     Batch 65/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 2s 16ms/step - loss: 14.0120 - StartIdxProbs_loss: 6.8505 - EndIdxProbs_loss: 6.9870 - StartIdxProbs_categorical_accuracy: 0.0261 - EndIdxProbs_categorical_accuracy: 0.0087 - val_loss: 13.3745 - val_StartIdxProbs_loss: 6.6188 - val_EndIdxProbs_loss: 6.5803 - val_StartIdxProbs_categorical_accuracy: 0.0000e+00 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 1/1     Batch 66/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 2s 16ms/step - loss: 14.2500 - StartIdxProbs_loss: 7.0657 - EndIdxProbs_loss: 7.0089 - StartIdxProbs_categorical_accuracy: 0.0000e+00 - EndIdxProbs_categorical_accuracy: 0.0000e+00 - val_loss: 14.2650 - val_StartIdxProbs_loss: 7.0114 - val_EndIdxProbs_loss: 7.0773 - val_StartIdxProbs_categorical_accuracy: 0.0000e+00 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 1/1     Batch 67/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 2s 16ms/step - loss: 14.3425 - StartIdxProbs_loss: 7.0766 - EndIdxProbs_loss: 7.0898 - StartIdxProbs_categorical_accuracy: 0.0000e+00 - EndIdxProbs_categorical_accuracy: 0.0000e+00 - val_loss: 15.1972 - val_StartIdxProbs_loss: 7.6253 - val_EndIdxProbs_loss: 7.3950 - val_StartIdxProbs_categorical_accuracy: 0.0000e+00 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 1/1     Batch 68/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 2s 16ms/step - loss: 14.5306 - StartIdxProbs_loss: 7.2222 - EndIdxProbs_loss: 7.1315 - StartIdxProbs_categorical_accuracy: 0.0000e+00 - EndIdxProbs_categorical_accuracy: 0.0000e+00 - val_loss: 13.7898 - val_StartIdxProbs_loss: 6.7896 - val_EndIdxProbs_loss: 6.8226 - val_StartIdxProbs_categorical_accuracy: 0.0000e+00 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/1     Batch 69/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 2s 17ms/step - loss: 13.7747 - StartIdxProbs_loss: 6.7790 - EndIdxProbs_loss: 6.8181 - StartIdxProbs_categorical_accuracy: 0.0087 - EndIdxProbs_categorical_accuracy: 0.0087 - val_loss: 13.6989 - val_StartIdxProbs_loss: 6.7595 - val_EndIdxProbs_loss: 6.7612 - val_StartIdxProbs_categorical_accuracy: 0.0769 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 1/1     Batch 70/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 2s 16ms/step - loss: 14.3046 - StartIdxProbs_loss: 7.0060 - EndIdxProbs_loss: 7.1204 - StartIdxProbs_categorical_accuracy: 0.0522 - EndIdxProbs_categorical_accuracy: 0.0261 - val_loss: 13.6220 - val_StartIdxProbs_loss: 6.8039 - val_EndIdxProbs_loss: 6.6393 - val_StartIdxProbs_categorical_accuracy: 0.0000e+00 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 1/1     Batch 71/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 2s 15ms/step - loss: 13.6466 - StartIdxProbs_loss: 6.7417 - EndIdxProbs_loss: 6.7262 - StartIdxProbs_categorical_accuracy: 0.0435 - EndIdxProbs_categorical_accuracy: 0.0000e+00 - val_loss: 14.6794 - val_StartIdxProbs_loss: 7.5688 - val_EndIdxProbs_loss: 6.9313 - val_StartIdxProbs_categorical_accuracy: 0.0000e+00 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 1/1     Batch 72/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 2s 15ms/step - loss: 14.0760 - StartIdxProbs_loss: 6.8764 - EndIdxProbs_loss: 7.0203 - StartIdxProbs_categorical_accuracy: 0.0174 - EndIdxProbs_categorical_accuracy: 0.0087 - val_loss: 13.5810 - val_StartIdxProbs_loss: 6.8014 - val_EndIdxProbs_loss: 6.5998 - val_StartIdxProbs_categorical_accuracy: 0.0000e+00 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 1/1     Batch 73/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 2s 16ms/step - loss: 13.6285 - StartIdxProbs_loss: 6.6929 - EndIdxProbs_loss: 6.7558 - StartIdxProbs_categorical_accuracy: 0.0087 - EndIdxProbs_categorical_accuracy: 0.0000e+00 - val_loss: 13.7952 - val_StartIdxProbs_loss: 6.9824 - val_EndIdxProbs_loss: 6.6326 - val_StartIdxProbs_categorical_accuracy: 0.0000e+00 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 1/1     Batch 74/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 2s 15ms/step - loss: 14.2981 - StartIdxProbs_loss: 7.0506 - EndIdxProbs_loss: 7.0673 - StartIdxProbs_categorical_accuracy: 0.0087 - EndIdxProbs_categorical_accuracy: 0.0000e+00 - val_loss: 13.1326 - val_StartIdxProbs_loss: 6.5636 - val_EndIdxProbs_loss: 6.3884 - val_StartIdxProbs_categorical_accuracy: 0.0000e+00 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 1/1     Batch 75/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 2s 15ms/step - loss: 13.9664 - StartIdxProbs_loss: 6.8575 - EndIdxProbs_loss: 6.9283 - StartIdxProbs_categorical_accuracy: 0.0087 - EndIdxProbs_categorical_accuracy: 0.0000e+00 - val_loss: 14.0758 - val_StartIdxProbs_loss: 6.8463 - val_EndIdxProbs_loss: 7.0485 - val_StartIdxProbs_categorical_accuracy: 0.0000e+00 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 1/1     Batch 76/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 2s 15ms/step - loss: 13.6027 - StartIdxProbs_loss: 6.6964 - EndIdxProbs_loss: 6.7253 - StartIdxProbs_categorical_accuracy: 0.0087 - EndIdxProbs_categorical_accuracy: 0.0000e+00 - val_loss: 13.5980 - val_StartIdxProbs_loss: 6.7606 - val_EndIdxProbs_loss: 6.6561 - val_StartIdxProbs_categorical_accuracy: 0.0769 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 1/1     Batch 77/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 2s 16ms/step - loss: 13.8483 - StartIdxProbs_loss: 6.8123 - EndIdxProbs_loss: 6.8546 - StartIdxProbs_categorical_accuracy: 0.0261 - EndIdxProbs_categorical_accuracy: 0.0087 - val_loss: 13.5062 - val_StartIdxProbs_loss: 6.5582 - val_EndIdxProbs_loss: 6.7663 - val_StartIdxProbs_categorical_accuracy: 0.0000e+00 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 1/1     Batch 78/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 2s 18ms/step - loss: 13.4099 - StartIdxProbs_loss: 6.6623 - EndIdxProbs_loss: 6.5660 - StartIdxProbs_categorical_accuracy: 0.0174 - EndIdxProbs_categorical_accuracy: 0.0000e+00 - val_loss: 13.6716 - val_StartIdxProbs_loss: 6.6543 - val_EndIdxProbs_loss: 6.8354 - val_StartIdxProbs_categorical_accuracy: 0.0769 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 1/1     Batch 79/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 2s 16ms/step - loss: 13.5477 - StartIdxProbs_loss: 6.5350 - EndIdxProbs_loss: 6.8308 - StartIdxProbs_categorical_accuracy: 0.0435 - EndIdxProbs_categorical_accuracy: 0.0087 - val_loss: 13.5350 - val_StartIdxProbs_loss: 6.6920 - val_EndIdxProbs_loss: 6.6609 - val_StartIdxProbs_categorical_accuracy: 0.0000e+00 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 1/1     Batch 80/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 2s 17ms/step - loss: 13.6190 - StartIdxProbs_loss: 6.6445 - EndIdxProbs_loss: 6.7923 - StartIdxProbs_categorical_accuracy: 0.0435 - EndIdxProbs_categorical_accuracy: 0.0000e+00 - val_loss: 13.1200 - val_StartIdxProbs_loss: 6.2423 - val_EndIdxProbs_loss: 6.6953 - val_StartIdxProbs_categorical_accuracy: 0.0769 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 1/1     Batch 81/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 2s 15ms/step - loss: 13.1069 - StartIdxProbs_loss: 6.3889 - EndIdxProbs_loss: 6.5356 - StartIdxProbs_categorical_accuracy: 0.0348 - EndIdxProbs_categorical_accuracy: 0.0261 - val_loss: 13.1213 - val_StartIdxProbs_loss: 6.3374 - val_EndIdxProbs_loss: 6.6013 - val_StartIdxProbs_categorical_accuracy: 0.0000e+00 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 1/1     Batch 82/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 2s 18ms/step - loss: 13.4959 - StartIdxProbs_loss: 6.6074 - EndIdxProbs_loss: 6.7059 - StartIdxProbs_categorical_accuracy: 0.0000e+00 - EndIdxProbs_categorical_accuracy: 0.0000e+00 - val_loss: 13.1922 - val_StartIdxProbs_loss: 6.5628 - val_EndIdxProbs_loss: 6.4465 - val_StartIdxProbs_categorical_accuracy: 0.0000e+00 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 1/1     Batch 83/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 2s 19ms/step - loss: 13.0271 - StartIdxProbs_loss: 6.3055 - EndIdxProbs_loss: 6.5387 - StartIdxProbs_categorical_accuracy: 0.0609 - EndIdxProbs_categorical_accuracy: 0.0000e+00 - val_loss: 12.2894 - val_StartIdxProbs_loss: 5.7881 - val_EndIdxProbs_loss: 6.3183 - val_StartIdxProbs_categorical_accuracy: 0.2308 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 1/1     Batch 84/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 3s 25ms/step - loss: 13.3014 - StartIdxProbs_loss: 6.4535 - EndIdxProbs_loss: 6.6648 - StartIdxProbs_categorical_accuracy: 0.0783 - EndIdxProbs_categorical_accuracy: 0.0000e+00 - val_loss: 13.1790 - val_StartIdxProbs_loss: 6.3255 - val_EndIdxProbs_loss: 6.6702 - val_StartIdxProbs_categorical_accuracy: 0.0769 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 1/1     Batch 85/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 2s 19ms/step - loss: 13.2855 - StartIdxProbs_loss: 6.5073 - EndIdxProbs_loss: 6.5950 - StartIdxProbs_categorical_accuracy: 0.0087 - EndIdxProbs_categorical_accuracy: 0.0087 - val_loss: 12.9963 - val_StartIdxProbs_loss: 6.2348 - val_EndIdxProbs_loss: 6.5781 - val_StartIdxProbs_categorical_accuracy: 0.0769 - val_EndIdxProbs_categorical_accuracy: 0.0769\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/1     Batch 86/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 2s 18ms/step - loss: 14.1422 - StartIdxProbs_loss: 6.9563 - EndIdxProbs_loss: 7.0025 - StartIdxProbs_categorical_accuracy: 0.0174 - EndIdxProbs_categorical_accuracy: 0.0000e+00 - val_loss: 14.1253 - val_StartIdxProbs_loss: 7.0826 - val_EndIdxProbs_loss: 6.8591 - val_StartIdxProbs_categorical_accuracy: 0.0000e+00 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 1/1     Batch 87/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 3s 22ms/step - loss: 13.8696 - StartIdxProbs_loss: 6.8180 - EndIdxProbs_loss: 6.8680 - StartIdxProbs_categorical_accuracy: 0.0174 - EndIdxProbs_categorical_accuracy: 0.0000e+00 - val_loss: 16.2622 - val_StartIdxProbs_loss: 8.0646 - val_EndIdxProbs_loss: 8.0140 - val_StartIdxProbs_categorical_accuracy: 0.0000e+00 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 1/1     Batch 88/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 3s 25ms/step - loss: 14.8511 - StartIdxProbs_loss: 7.3562 - EndIdxProbs_loss: 7.3112 - StartIdxProbs_categorical_accuracy: 0.0087 - EndIdxProbs_categorical_accuracy: 0.0000e+00 - val_loss: 12.4597 - val_StartIdxProbs_loss: 5.9577 - val_EndIdxProbs_loss: 6.3183 - val_StartIdxProbs_categorical_accuracy: 0.1538 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 1/1     Batch 89/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 2s 17ms/step - loss: 13.6547 - StartIdxProbs_loss: 6.7042 - EndIdxProbs_loss: 6.7667 - StartIdxProbs_categorical_accuracy: 0.0087 - EndIdxProbs_categorical_accuracy: 0.0087 - val_loss: 13.1134 - val_StartIdxProbs_loss: 6.0669 - val_EndIdxProbs_loss: 6.8627 - val_StartIdxProbs_categorical_accuracy: 0.1538 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 1/1     Batch 90/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 3s 29ms/step - loss: 13.0864 - StartIdxProbs_loss: 6.4122 - EndIdxProbs_loss: 6.4904 - StartIdxProbs_categorical_accuracy: 0.0435 - EndIdxProbs_categorical_accuracy: 0.0000e+00 - val_loss: 12.5741 - val_StartIdxProbs_loss: 6.1939 - val_EndIdxProbs_loss: 6.1964 - val_StartIdxProbs_categorical_accuracy: 0.0000e+00 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 1/1     Batch 91/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 2s 18ms/step - loss: 13.1968 - StartIdxProbs_loss: 6.4933 - EndIdxProbs_loss: 6.5197 - StartIdxProbs_categorical_accuracy: 0.0174 - EndIdxProbs_categorical_accuracy: 0.0087 - val_loss: 13.1826 - val_StartIdxProbs_loss: 6.4687 - val_EndIdxProbs_loss: 6.5300 - val_StartIdxProbs_categorical_accuracy: 0.0000e+00 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 1/1     Batch 92/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 4s 33ms/step - loss: 13.5235 - StartIdxProbs_loss: 6.6095 - EndIdxProbs_loss: 6.7301 - StartIdxProbs_categorical_accuracy: 0.0174 - EndIdxProbs_categorical_accuracy: 0.0087 - val_loss: 12.9917 - val_StartIdxProbs_loss: 6.3020 - val_EndIdxProbs_loss: 6.5058 - val_StartIdxProbs_categorical_accuracy: 0.0769 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 1/1     Batch 93/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 2s 16ms/step - loss: 13.3301 - StartIdxProbs_loss: 6.5770 - EndIdxProbs_loss: 6.5692 - StartIdxProbs_categorical_accuracy: 0.0000e+00 - EndIdxProbs_categorical_accuracy: 0.0000e+00 - val_loss: 13.2901 - val_StartIdxProbs_loss: 6.5888 - val_EndIdxProbs_loss: 6.5174 - val_StartIdxProbs_categorical_accuracy: 0.0000e+00 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 1/1     Batch 94/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 2s 17ms/step - loss: 12.9419 - StartIdxProbs_loss: 6.3163 - EndIdxProbs_loss: 6.4416 - StartIdxProbs_categorical_accuracy: 0.0174 - EndIdxProbs_categorical_accuracy: 0.0000e+00 - val_loss: 12.4184 - val_StartIdxProbs_loss: 5.9942 - val_EndIdxProbs_loss: 6.2401 - val_StartIdxProbs_categorical_accuracy: 0.1538 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 1/1     Batch 95/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 2s 18ms/step - loss: 12.7708 - StartIdxProbs_loss: 6.2109 - EndIdxProbs_loss: 6.3758 - StartIdxProbs_categorical_accuracy: 0.0435 - EndIdxProbs_categorical_accuracy: 0.0087 - val_loss: 12.4751 - val_StartIdxProbs_loss: 6.0815 - val_EndIdxProbs_loss: 6.2096 - val_StartIdxProbs_categorical_accuracy: 0.0000e+00 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 1/1     Batch 96/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 2s 17ms/step - loss: 13.1523 - StartIdxProbs_loss: 6.4330 - EndIdxProbs_loss: 6.5353 - StartIdxProbs_categorical_accuracy: 0.0435 - EndIdxProbs_categorical_accuracy: 0.0000e+00 - val_loss: 12.8662 - val_StartIdxProbs_loss: 6.2668 - val_EndIdxProbs_loss: 6.4154 - val_StartIdxProbs_categorical_accuracy: 0.0769 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 1/1     Batch 97/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 2s 16ms/step - loss: 13.3976 - StartIdxProbs_loss: 6.5794 - EndIdxProbs_loss: 6.6342 - StartIdxProbs_categorical_accuracy: 0.0435 - EndIdxProbs_categorical_accuracy: 0.0000e+00 - val_loss: 13.0286 - val_StartIdxProbs_loss: 6.4566 - val_EndIdxProbs_loss: 6.3879 - val_StartIdxProbs_categorical_accuracy: 0.0000e+00 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 1/1     Batch 98/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 2s 16ms/step - loss: 13.3954 - StartIdxProbs_loss: 6.5626 - EndIdxProbs_loss: 6.6487 - StartIdxProbs_categorical_accuracy: 0.0261 - EndIdxProbs_categorical_accuracy: 0.0000e+00 - val_loss: 13.1216 - val_StartIdxProbs_loss: 6.2574 - val_EndIdxProbs_loss: 6.6801 - val_StartIdxProbs_categorical_accuracy: 0.1538 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 1/1     Batch 99/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 2s 17ms/step - loss: 13.5619 - StartIdxProbs_loss: 6.6551 - EndIdxProbs_loss: 6.7227 - StartIdxProbs_categorical_accuracy: 0.0174 - EndIdxProbs_categorical_accuracy: 0.0087 - val_loss: 13.6495 - val_StartIdxProbs_loss: 6.7460 - val_EndIdxProbs_loss: 6.7195 - val_StartIdxProbs_categorical_accuracy: 0.0000e+00 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 1/1     Batch 100/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 3s 26ms/step - loss: 13.8811 - StartIdxProbs_loss: 6.8724 - EndIdxProbs_loss: 6.8247 - StartIdxProbs_categorical_accuracy: 0.0087 - EndIdxProbs_categorical_accuracy: 0.0000e+00 - val_loss: 12.8961 - val_StartIdxProbs_loss: 6.2704 - val_EndIdxProbs_loss: 6.4417 - val_StartIdxProbs_categorical_accuracy: 0.0000e+00 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 1/1     Batch 101/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 3s 23ms/step - loss: 12.9038 - StartIdxProbs_loss: 6.3156 - EndIdxProbs_loss: 6.4043 - StartIdxProbs_categorical_accuracy: 0.0087 - EndIdxProbs_categorical_accuracy: 0.0000e+00 - val_loss: 12.9798 - val_StartIdxProbs_loss: 6.3800 - val_EndIdxProbs_loss: 6.4158 - val_StartIdxProbs_categorical_accuracy: 0.0000e+00 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 1/1     Batch 102/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 3s 25ms/step - loss: 13.2188 - StartIdxProbs_loss: 6.5313 - EndIdxProbs_loss: 6.5036 - StartIdxProbs_categorical_accuracy: 0.0174 - EndIdxProbs_categorical_accuracy: 0.0000e+00 - val_loss: 12.8040 - val_StartIdxProbs_loss: 6.1167 - val_EndIdxProbs_loss: 6.5034 - val_StartIdxProbs_categorical_accuracy: 0.0000e+00 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/1     Batch 103/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 2s 19ms/step - loss: 13.6166 - StartIdxProbs_loss: 6.6475 - EndIdxProbs_loss: 6.7853 - StartIdxProbs_categorical_accuracy: 0.0435 - EndIdxProbs_categorical_accuracy: 0.0000e+00 - val_loss: 12.7597 - val_StartIdxProbs_loss: 6.2823 - val_EndIdxProbs_loss: 6.2936 - val_StartIdxProbs_categorical_accuracy: 0.0000e+00 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 1/1     Batch 104/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 2s 16ms/step - loss: 13.2190 - StartIdxProbs_loss: 6.5267 - EndIdxProbs_loss: 6.5085 - StartIdxProbs_categorical_accuracy: 0.0087 - EndIdxProbs_categorical_accuracy: 0.0000e+00 - val_loss: 13.6469 - val_StartIdxProbs_loss: 6.5806 - val_EndIdxProbs_loss: 6.8826 - val_StartIdxProbs_categorical_accuracy: 0.0000e+00 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 1/1     Batch 105/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 2s 18ms/step - loss: 13.2139 - StartIdxProbs_loss: 6.4976 - EndIdxProbs_loss: 6.5326 - StartIdxProbs_categorical_accuracy: 0.0087 - EndIdxProbs_categorical_accuracy: 0.0000e+00 - val_loss: 12.4261 - val_StartIdxProbs_loss: 5.9005 - val_EndIdxProbs_loss: 6.3419 - val_StartIdxProbs_categorical_accuracy: 0.0769 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 1/1     Batch 106/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 2s 17ms/step - loss: 13.6004 - StartIdxProbs_loss: 6.6635 - EndIdxProbs_loss: 6.7532 - StartIdxProbs_categorical_accuracy: 0.0348 - EndIdxProbs_categorical_accuracy: 0.0087 - val_loss: 13.1715 - val_StartIdxProbs_loss: 6.3758 - val_EndIdxProbs_loss: 6.6121 - val_StartIdxProbs_categorical_accuracy: 0.0000e+00 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 1/1     Batch 107/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 2s 18ms/step - loss: 13.1593 - StartIdxProbs_loss: 6.4439 - EndIdxProbs_loss: 6.5318 - StartIdxProbs_categorical_accuracy: 0.0174 - EndIdxProbs_categorical_accuracy: 0.0000e+00 - val_loss: 13.2127 - val_StartIdxProbs_loss: 6.5620 - val_EndIdxProbs_loss: 6.4672 - val_StartIdxProbs_categorical_accuracy: 0.0000e+00 - val_EndIdxProbs_categorical_accuracy: 0.0769\n",
      "\n",
      "Epoch 1/1     Batch 108/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 2s 19ms/step - loss: 13.3383 - StartIdxProbs_loss: 6.5686 - EndIdxProbs_loss: 6.5862 - StartIdxProbs_categorical_accuracy: 0.0000e+00 - EndIdxProbs_categorical_accuracy: 0.0000e+00 - val_loss: 12.8970 - val_StartIdxProbs_loss: 6.1812 - val_EndIdxProbs_loss: 6.5324 - val_StartIdxProbs_categorical_accuracy: 0.0769 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 1/1     Batch 109/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 2s 21ms/step - loss: 13.6024 - StartIdxProbs_loss: 6.6919 - EndIdxProbs_loss: 6.7270 - StartIdxProbs_categorical_accuracy: 0.0261 - EndIdxProbs_categorical_accuracy: 0.0000e+00 - val_loss: 14.1116 - val_StartIdxProbs_loss: 7.0483 - val_EndIdxProbs_loss: 6.8800 - val_StartIdxProbs_categorical_accuracy: 0.0000e+00 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 1/1     Batch 110/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 2s 16ms/step - loss: 13.5793 - StartIdxProbs_loss: 6.6820 - EndIdxProbs_loss: 6.7140 - StartIdxProbs_categorical_accuracy: 0.0261 - EndIdxProbs_categorical_accuracy: 0.0000e+00 - val_loss: 13.1474 - val_StartIdxProbs_loss: 6.3884 - val_EndIdxProbs_loss: 6.5758 - val_StartIdxProbs_categorical_accuracy: 0.0000e+00 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 1/1     Batch 111/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 3s 22ms/step - loss: 13.8338 - StartIdxProbs_loss: 6.7606 - EndIdxProbs_loss: 6.8901 - StartIdxProbs_categorical_accuracy: 0.0087 - EndIdxProbs_categorical_accuracy: 0.0000e+00 - val_loss: 12.1948 - val_StartIdxProbs_loss: 5.9116 - val_EndIdxProbs_loss: 6.1002 - val_StartIdxProbs_categorical_accuracy: 0.1538 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 1/1     Batch 112/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 2s 21ms/step - loss: 12.8131 - StartIdxProbs_loss: 6.2093 - EndIdxProbs_loss: 6.4207 - StartIdxProbs_categorical_accuracy: 0.0870 - EndIdxProbs_categorical_accuracy: 0.0000e+00 - val_loss: 13.9039 - val_StartIdxProbs_loss: 6.8618 - val_EndIdxProbs_loss: 6.8592 - val_StartIdxProbs_categorical_accuracy: 0.0000e+00 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 1/1     Batch 113/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 2s 16ms/step - loss: 12.9257 - StartIdxProbs_loss: 6.3233 - EndIdxProbs_loss: 6.4195 - StartIdxProbs_categorical_accuracy: 0.0174 - EndIdxProbs_categorical_accuracy: 0.0000e+00 - val_loss: 13.7351 - val_StartIdxProbs_loss: 6.7069 - val_EndIdxProbs_loss: 6.8455 - val_StartIdxProbs_categorical_accuracy: 0.0000e+00 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 1/1     Batch 114/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 2s 17ms/step - loss: 13.2895 - StartIdxProbs_loss: 6.5011 - EndIdxProbs_loss: 6.6056 - StartIdxProbs_categorical_accuracy: 0.0261 - EndIdxProbs_categorical_accuracy: 0.0000e+00 - val_loss: 12.9193 - val_StartIdxProbs_loss: 6.3617 - val_EndIdxProbs_loss: 6.3751 - val_StartIdxProbs_categorical_accuracy: 0.0000e+00 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 1/1     Batch 115/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 2s 19ms/step - loss: 13.3261 - StartIdxProbs_loss: 6.4924 - EndIdxProbs_loss: 6.6511 - StartIdxProbs_categorical_accuracy: 0.0522 - EndIdxProbs_categorical_accuracy: 0.0000e+00 - val_loss: 13.4384 - val_StartIdxProbs_loss: 6.3701 - val_EndIdxProbs_loss: 6.8859 - val_StartIdxProbs_categorical_accuracy: 0.0769 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 1/1     Batch 116/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 2s 19ms/step - loss: 13.7825 - StartIdxProbs_loss: 6.7720 - EndIdxProbs_loss: 6.8281 - StartIdxProbs_categorical_accuracy: 0.0174 - EndIdxProbs_categorical_accuracy: 0.0000e+00 - val_loss: 13.4796 - val_StartIdxProbs_loss: 6.5231 - val_EndIdxProbs_loss: 6.7743 - val_StartIdxProbs_categorical_accuracy: 0.0769 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 1/1     Batch 117/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 2s 18ms/step - loss: 12.8441 - StartIdxProbs_loss: 6.2444 - EndIdxProbs_loss: 6.4174 - StartIdxProbs_categorical_accuracy: 0.0435 - EndIdxProbs_categorical_accuracy: 0.0087 - val_loss: 13.6159 - val_StartIdxProbs_loss: 6.7543 - val_EndIdxProbs_loss: 6.6794 - val_StartIdxProbs_categorical_accuracy: 0.0000e+00 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 1/1     Batch 118/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 2s 21ms/step - loss: 13.3109 - StartIdxProbs_loss: 6.5451 - EndIdxProbs_loss: 6.5837 - StartIdxProbs_categorical_accuracy: 0.0000e+00 - EndIdxProbs_categorical_accuracy: 0.0000e+00 - val_loss: 13.5945 - val_StartIdxProbs_loss: 6.6067 - val_EndIdxProbs_loss: 6.8059 - val_StartIdxProbs_categorical_accuracy: 0.0000e+00 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 1/1     Batch 119/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 2s 15ms/step - loss: 13.1381 - StartIdxProbs_loss: 6.4025 - EndIdxProbs_loss: 6.5537 - StartIdxProbs_categorical_accuracy: 0.0087 - EndIdxProbs_categorical_accuracy: 0.0000e+00 - val_loss: 12.1571 - val_StartIdxProbs_loss: 5.9887 - val_EndIdxProbs_loss: 5.9866 - val_StartIdxProbs_categorical_accuracy: 0.0000e+00 - val_EndIdxProbs_categorical_accuracy: 0.0769\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/1     Batch 120/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 2s 19ms/step - loss: 13.3736 - StartIdxProbs_loss: 6.5957 - EndIdxProbs_loss: 6.5962 - StartIdxProbs_categorical_accuracy: 0.0000e+00 - EndIdxProbs_categorical_accuracy: 0.0000e+00 - val_loss: 15.9903 - val_StartIdxProbs_loss: 8.1212 - val_EndIdxProbs_loss: 7.6876 - val_StartIdxProbs_categorical_accuracy: 0.0000e+00 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 1/1     Batch 121/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 2s 18ms/step - loss: 13.6161 - StartIdxProbs_loss: 6.6857 - EndIdxProbs_loss: 6.7488 - StartIdxProbs_categorical_accuracy: 0.0174 - EndIdxProbs_categorical_accuracy: 0.0174 - val_loss: 12.9379 - val_StartIdxProbs_loss: 6.5017 - val_EndIdxProbs_loss: 6.2549 - val_StartIdxProbs_categorical_accuracy: 0.0000e+00 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 1/1     Batch 122/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 2s 18ms/step - loss: 13.1368 - StartIdxProbs_loss: 6.4269 - EndIdxProbs_loss: 6.5285 - StartIdxProbs_categorical_accuracy: 0.0348 - EndIdxProbs_categorical_accuracy: 0.0087 - val_loss: 12.8931 - val_StartIdxProbs_loss: 6.1543 - val_EndIdxProbs_loss: 6.5576 - val_StartIdxProbs_categorical_accuracy: 0.0000e+00 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 1/1     Batch 123/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 2s 16ms/step - loss: 13.2767 - StartIdxProbs_loss: 6.5223 - EndIdxProbs_loss: 6.5732 - StartIdxProbs_categorical_accuracy: 0.0435 - EndIdxProbs_categorical_accuracy: 0.0087 - val_loss: 12.8625 - val_StartIdxProbs_loss: 6.2150 - val_EndIdxProbs_loss: 6.4665 - val_StartIdxProbs_categorical_accuracy: 0.0769 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 1/1     Batch 124/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 2s 20ms/step - loss: 13.7511 - StartIdxProbs_loss: 6.7462 - EndIdxProbs_loss: 6.8238 - StartIdxProbs_categorical_accuracy: 0.0000e+00 - EndIdxProbs_categorical_accuracy: 0.0261 - val_loss: 12.7606 - val_StartIdxProbs_loss: 6.4229 - val_EndIdxProbs_loss: 6.1570 - val_StartIdxProbs_categorical_accuracy: 0.0000e+00 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 1/1     Batch 125/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 3s 22ms/step - loss: 13.8708 - StartIdxProbs_loss: 6.8196 - EndIdxProbs_loss: 6.8705 - StartIdxProbs_categorical_accuracy: 0.0087 - EndIdxProbs_categorical_accuracy: 0.0000e+00 - val_loss: 13.3065 - val_StartIdxProbs_loss: 6.5122 - val_EndIdxProbs_loss: 6.6138 - val_StartIdxProbs_categorical_accuracy: 0.0000e+00 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 1/1     Batch 126/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 2s 21ms/step - loss: 14.0670 - StartIdxProbs_loss: 6.9002 - EndIdxProbs_loss: 6.9863 - StartIdxProbs_categorical_accuracy: 0.0435 - EndIdxProbs_categorical_accuracy: 0.0087 - val_loss: 13.2500 - val_StartIdxProbs_loss: 6.3738 - val_EndIdxProbs_loss: 6.6960 - val_StartIdxProbs_categorical_accuracy: 0.0769 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 1/1     Batch 127/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 2s 19ms/step - loss: 13.4265 - StartIdxProbs_loss: 6.5347 - EndIdxProbs_loss: 6.7115 - StartIdxProbs_categorical_accuracy: 0.0609 - EndIdxProbs_categorical_accuracy: 0.0000e+00 - val_loss: 13.3573 - val_StartIdxProbs_loss: 6.5593 - val_EndIdxProbs_loss: 6.6180 - val_StartIdxProbs_categorical_accuracy: 0.0000e+00 - val_EndIdxProbs_categorical_accuracy: 0.0769\n",
      "\n",
      "Epoch 1/1     Batch 128/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 2s 19ms/step - loss: 13.7751 - StartIdxProbs_loss: 6.7349 - EndIdxProbs_loss: 6.8601 - StartIdxProbs_categorical_accuracy: 0.0348 - EndIdxProbs_categorical_accuracy: 0.0000e+00 - val_loss: 13.6817 - val_StartIdxProbs_loss: 6.8616 - val_EndIdxProbs_loss: 6.6403 - val_StartIdxProbs_categorical_accuracy: 0.0000e+00 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 1/1     Batch 129/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 2s 17ms/step - loss: 13.7326 - StartIdxProbs_loss: 6.7297 - EndIdxProbs_loss: 6.8231 - StartIdxProbs_categorical_accuracy: 0.0000e+00 - EndIdxProbs_categorical_accuracy: 0.0087 - val_loss: 13.0024 - val_StartIdxProbs_loss: 6.4481 - val_EndIdxProbs_loss: 6.3747 - val_StartIdxProbs_categorical_accuracy: 0.0000e+00 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 1/1     Batch 130/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 2s 17ms/step - loss: 13.1303 - StartIdxProbs_loss: 6.4190 - EndIdxProbs_loss: 6.5317 - StartIdxProbs_categorical_accuracy: 0.0609 - EndIdxProbs_categorical_accuracy: 0.0087 - val_loss: 12.9914 - val_StartIdxProbs_loss: 6.2249 - val_EndIdxProbs_loss: 6.5872 - val_StartIdxProbs_categorical_accuracy: 0.0769 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 1/1     Batch 131/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 2s 16ms/step - loss: 12.9818 - StartIdxProbs_loss: 6.3719 - EndIdxProbs_loss: 6.4306 - StartIdxProbs_categorical_accuracy: 0.0348 - EndIdxProbs_categorical_accuracy: 0.0000e+00 - val_loss: 14.9268 - val_StartIdxProbs_loss: 7.4500 - val_EndIdxProbs_loss: 7.2977 - val_StartIdxProbs_categorical_accuracy: 0.0000e+00 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 1/1     Batch 132/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 2s 15ms/step - loss: 13.5020 - StartIdxProbs_loss: 6.5605 - EndIdxProbs_loss: 6.7624 - StartIdxProbs_categorical_accuracy: 0.0696 - EndIdxProbs_categorical_accuracy: 0.0000e+00 - val_loss: 15.2456 - val_StartIdxProbs_loss: 7.4997 - val_EndIdxProbs_loss: 7.5670 - val_StartIdxProbs_categorical_accuracy: 0.0000e+00 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 1/1     Batch 133/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 2s 15ms/step - loss: 14.0388 - StartIdxProbs_loss: 6.9369 - EndIdxProbs_loss: 6.9230 - StartIdxProbs_categorical_accuracy: 0.0261 - EndIdxProbs_categorical_accuracy: 0.0087 - val_loss: 12.4934 - val_StartIdxProbs_loss: 6.1629 - val_EndIdxProbs_loss: 6.1519 - val_StartIdxProbs_categorical_accuracy: 0.0000e+00 - val_EndIdxProbs_categorical_accuracy: 0.0769\n",
      "\n",
      "Epoch 1/1     Batch 134/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 2s 17ms/step - loss: 13.2594 - StartIdxProbs_loss: 6.4622 - EndIdxProbs_loss: 6.6186 - StartIdxProbs_categorical_accuracy: 0.0435 - EndIdxProbs_categorical_accuracy: 0.0174 - val_loss: 14.3495 - val_StartIdxProbs_loss: 7.0616 - val_EndIdxProbs_loss: 7.1095 - val_StartIdxProbs_categorical_accuracy: 0.0000e+00 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 1/1     Batch 135/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 2s 17ms/step - loss: 13.4592 - StartIdxProbs_loss: 6.5732 - EndIdxProbs_loss: 6.7077 - StartIdxProbs_categorical_accuracy: 0.0609 - EndIdxProbs_categorical_accuracy: 0.0000e+00 - val_loss: 12.6302 - val_StartIdxProbs_loss: 6.2811 - val_EndIdxProbs_loss: 6.1709 - val_StartIdxProbs_categorical_accuracy: 0.0000e+00 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 1/1     Batch 136/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 2s 18ms/step - loss: 13.5405 - StartIdxProbs_loss: 6.5831 - EndIdxProbs_loss: 6.7793 - StartIdxProbs_categorical_accuracy: 0.0609 - EndIdxProbs_categorical_accuracy: 0.0000e+00 - val_loss: 13.0677 - val_StartIdxProbs_loss: 6.0784 - val_EndIdxProbs_loss: 6.8115 - val_StartIdxProbs_categorical_accuracy: 0.1538 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/1     Batch 137/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 2s 16ms/step - loss: 13.3099 - StartIdxProbs_loss: 6.4907 - EndIdxProbs_loss: 6.6414 - StartIdxProbs_categorical_accuracy: 0.0261 - EndIdxProbs_categorical_accuracy: 0.0087 - val_loss: 12.6588 - val_StartIdxProbs_loss: 6.2931 - val_EndIdxProbs_loss: 6.1880 - val_StartIdxProbs_categorical_accuracy: 0.0000e+00 - val_EndIdxProbs_categorical_accuracy: 0.0769\n",
      "\n",
      "Epoch 1/1     Batch 138/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 2s 19ms/step - loss: 13.4409 - StartIdxProbs_loss: 6.6193 - EndIdxProbs_loss: 6.6440 - StartIdxProbs_categorical_accuracy: 0.0174 - EndIdxProbs_categorical_accuracy: 0.0000e+00 - val_loss: 13.0838 - val_StartIdxProbs_loss: 6.4984 - val_EndIdxProbs_loss: 6.4080 - val_StartIdxProbs_categorical_accuracy: 0.0000e+00 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 1/1     Batch 139/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 2s 18ms/step - loss: 13.7316 - StartIdxProbs_loss: 6.7787 - EndIdxProbs_loss: 6.7756 - StartIdxProbs_categorical_accuracy: 0.0000e+00 - EndIdxProbs_categorical_accuracy: 0.0000e+00 - val_loss: 13.2142 - val_StartIdxProbs_loss: 6.5103 - val_EndIdxProbs_loss: 6.5267 - val_StartIdxProbs_categorical_accuracy: 0.0000e+00 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 1/1     Batch 140/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 2s 15ms/step - loss: 13.1758 - StartIdxProbs_loss: 6.5132 - EndIdxProbs_loss: 6.4855 - StartIdxProbs_categorical_accuracy: 0.0000e+00 - EndIdxProbs_categorical_accuracy: 0.0174 - val_loss: 12.9973 - val_StartIdxProbs_loss: 6.4019 - val_EndIdxProbs_loss: 6.4185 - val_StartIdxProbs_categorical_accuracy: 0.0000e+00 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 1/1     Batch 141/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 2s 15ms/step - loss: 13.1701 - StartIdxProbs_loss: 6.4185 - EndIdxProbs_loss: 6.5746 - StartIdxProbs_categorical_accuracy: 0.0435 - EndIdxProbs_categorical_accuracy: 0.0087 - val_loss: 13.0515 - val_StartIdxProbs_loss: 6.4361 - val_EndIdxProbs_loss: 6.4387 - val_StartIdxProbs_categorical_accuracy: 0.0769 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 1/1     Batch 142/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 2s 15ms/step - loss: 12.8913 - StartIdxProbs_loss: 6.2820 - EndIdxProbs_loss: 6.4326 - StartIdxProbs_categorical_accuracy: 0.0435 - EndIdxProbs_categorical_accuracy: 0.0000e+00 - val_loss: 12.9720 - val_StartIdxProbs_loss: 6.3211 - val_EndIdxProbs_loss: 6.4744 - val_StartIdxProbs_categorical_accuracy: 0.0769 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 1/1     Batch 143/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 2s 15ms/step - loss: 13.9280 - StartIdxProbs_loss: 6.7974 - EndIdxProbs_loss: 6.9541 - StartIdxProbs_categorical_accuracy: 0.0174 - EndIdxProbs_categorical_accuracy: 0.0087 - val_loss: 15.1195 - val_StartIdxProbs_loss: 7.5390 - val_EndIdxProbs_loss: 7.4042 - val_StartIdxProbs_categorical_accuracy: 0.0000e+00 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 1/1     Batch 144/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 2s 15ms/step - loss: 14.1420 - StartIdxProbs_loss: 6.9513 - EndIdxProbs_loss: 7.0144 - StartIdxProbs_categorical_accuracy: 0.0174 - EndIdxProbs_categorical_accuracy: 0.0000e+00 - val_loss: 13.2598 - val_StartIdxProbs_loss: 6.5585 - val_EndIdxProbs_loss: 6.5253 - val_StartIdxProbs_categorical_accuracy: 0.0000e+00 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 1/1     Batch 145/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 2s 15ms/step - loss: 13.5660 - StartIdxProbs_loss: 6.6056 - EndIdxProbs_loss: 6.7843 - StartIdxProbs_categorical_accuracy: 0.0174 - EndIdxProbs_categorical_accuracy: 0.0174 - val_loss: 13.8642 - val_StartIdxProbs_loss: 6.9647 - val_EndIdxProbs_loss: 6.7237 - val_StartIdxProbs_categorical_accuracy: 0.0000e+00 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 1/1     Batch 146/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 2s 15ms/step - loss: 13.3488 - StartIdxProbs_loss: 6.5022 - EndIdxProbs_loss: 6.6708 - StartIdxProbs_categorical_accuracy: 0.0348 - EndIdxProbs_categorical_accuracy: 0.0174 - val_loss: 12.4321 - val_StartIdxProbs_loss: 5.9871 - val_EndIdxProbs_loss: 6.2694 - val_StartIdxProbs_categorical_accuracy: 0.0769 - val_EndIdxProbs_categorical_accuracy: 0.0769\n",
      "\n",
      "Epoch 1/1     Batch 147/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 2s 16ms/step - loss: 13.4429 - StartIdxProbs_loss: 6.6596 - EndIdxProbs_loss: 6.6077 - StartIdxProbs_categorical_accuracy: 0.0087 - EndIdxProbs_categorical_accuracy: 0.0087 - val_loss: 13.1057 - val_StartIdxProbs_loss: 6.6530 - val_EndIdxProbs_loss: 6.2773 - val_StartIdxProbs_categorical_accuracy: 0.0000e+00 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 1/1     Batch 148/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 2s 18ms/step - loss: 13.0356 - StartIdxProbs_loss: 6.3879 - EndIdxProbs_loss: 6.4723 - StartIdxProbs_categorical_accuracy: 0.0000e+00 - EndIdxProbs_categorical_accuracy: 0.0087 - val_loss: 12.6521 - val_StartIdxProbs_loss: 6.2138 - val_EndIdxProbs_loss: 6.2630 - val_StartIdxProbs_categorical_accuracy: 0.0000e+00 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 1/1     Batch 149/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 2s 18ms/step - loss: 13.6400 - StartIdxProbs_loss: 6.6970 - EndIdxProbs_loss: 6.7679 - StartIdxProbs_categorical_accuracy: 0.0174 - EndIdxProbs_categorical_accuracy: 0.0087 - val_loss: 13.9053 - val_StartIdxProbs_loss: 6.7512 - val_EndIdxProbs_loss: 6.9791 - val_StartIdxProbs_categorical_accuracy: 0.0769 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 1/1     Batch 150/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 2s 19ms/step - loss: 13.4807 - StartIdxProbs_loss: 6.5874 - EndIdxProbs_loss: 6.7183 - StartIdxProbs_categorical_accuracy: 0.0174 - EndIdxProbs_categorical_accuracy: 0.0435 - val_loss: 12.7667 - val_StartIdxProbs_loss: 6.0624 - val_EndIdxProbs_loss: 6.5296 - val_StartIdxProbs_categorical_accuracy: 0.0769 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 1/1     Batch 151/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 2s 17ms/step - loss: 14.7229 - StartIdxProbs_loss: 7.2789 - EndIdxProbs_loss: 7.2692 - StartIdxProbs_categorical_accuracy: 0.0174 - EndIdxProbs_categorical_accuracy: 0.0000e+00 - val_loss: 13.7210 - val_StartIdxProbs_loss: 6.5165 - val_EndIdxProbs_loss: 7.0299 - val_StartIdxProbs_categorical_accuracy: 0.0769 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 1/1     Batch 152/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 2s 16ms/step - loss: 14.1325 - StartIdxProbs_loss: 6.9848 - EndIdxProbs_loss: 6.9732 - StartIdxProbs_categorical_accuracy: 0.0174 - EndIdxProbs_categorical_accuracy: 0.0000e+00 - val_loss: 14.6544 - val_StartIdxProbs_loss: 7.0573 - val_EndIdxProbs_loss: 7.4228 - val_StartIdxProbs_categorical_accuracy: 0.0000e+00 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 1/1     Batch 153/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 2s 15ms/step - loss: 14.1435 - StartIdxProbs_loss: 6.9817 - EndIdxProbs_loss: 6.9874 - StartIdxProbs_categorical_accuracy: 0.0261 - EndIdxProbs_categorical_accuracy: 0.0174 - val_loss: 15.5384 - val_StartIdxProbs_loss: 7.5019 - val_EndIdxProbs_loss: 7.8624 - val_StartIdxProbs_categorical_accuracy: 0.0769 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/1     Batch 154/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 2s 16ms/step - loss: 13.6418 - StartIdxProbs_loss: 6.7000 - EndIdxProbs_loss: 6.7677 - StartIdxProbs_categorical_accuracy: 0.0348 - EndIdxProbs_categorical_accuracy: 0.0000e+00 - val_loss: 13.0306 - val_StartIdxProbs_loss: 6.2914 - val_EndIdxProbs_loss: 6.5653 - val_StartIdxProbs_categorical_accuracy: 0.0000e+00 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 1/1     Batch 155/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 2s 15ms/step - loss: 13.0799 - StartIdxProbs_loss: 6.3569 - EndIdxProbs_loss: 6.5492 - StartIdxProbs_categorical_accuracy: 0.0783 - EndIdxProbs_categorical_accuracy: 0.0000e+00 - val_loss: 12.5757 - val_StartIdxProbs_loss: 6.0282 - val_EndIdxProbs_loss: 6.3738 - val_StartIdxProbs_categorical_accuracy: 0.1538 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 1/1     Batch 156/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 2s 15ms/step - loss: 13.2240 - StartIdxProbs_loss: 6.4550 - EndIdxProbs_loss: 6.5954 - StartIdxProbs_categorical_accuracy: 0.0783 - EndIdxProbs_categorical_accuracy: 0.0174 - val_loss: 13.6560 - val_StartIdxProbs_loss: 6.7852 - val_EndIdxProbs_loss: 6.6972 - val_StartIdxProbs_categorical_accuracy: 0.0000e+00 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 1/1     Batch 157/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 2s 15ms/step - loss: 13.3878 - StartIdxProbs_loss: 6.5585 - EndIdxProbs_loss: 6.6558 - StartIdxProbs_categorical_accuracy: 0.0087 - EndIdxProbs_categorical_accuracy: 0.0087 - val_loss: 13.1078 - val_StartIdxProbs_loss: 6.4487 - val_EndIdxProbs_loss: 6.4857 - val_StartIdxProbs_categorical_accuracy: 0.0000e+00 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 1/1     Batch 158/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 2s 15ms/step - loss: 13.4822 - StartIdxProbs_loss: 6.5817 - EndIdxProbs_loss: 6.7272 - StartIdxProbs_categorical_accuracy: 0.0435 - EndIdxProbs_categorical_accuracy: 0.0000e+00 - val_loss: 13.3415 - val_StartIdxProbs_loss: 6.5719 - val_EndIdxProbs_loss: 6.5965 - val_StartIdxProbs_categorical_accuracy: 0.0769 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 1/1     Batch 159/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 2s 16ms/step - loss: 13.0334 - StartIdxProbs_loss: 6.3547 - EndIdxProbs_loss: 6.5055 - StartIdxProbs_categorical_accuracy: 0.0522 - EndIdxProbs_categorical_accuracy: 0.0000e+00 - val_loss: 12.7464 - val_StartIdxProbs_loss: 6.1088 - val_EndIdxProbs_loss: 6.4646 - val_StartIdxProbs_categorical_accuracy: 0.0769 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 1/1     Batch 160/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 2s 15ms/step - loss: 12.8168 - StartIdxProbs_loss: 6.2812 - EndIdxProbs_loss: 6.3627 - StartIdxProbs_categorical_accuracy: 0.0174 - EndIdxProbs_categorical_accuracy: 0.0087 - val_loss: 12.7951 - val_StartIdxProbs_loss: 6.2231 - val_EndIdxProbs_loss: 6.3992 - val_StartIdxProbs_categorical_accuracy: 0.0769 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 1/1     Batch 161/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 2s 15ms/step - loss: 12.6819 - StartIdxProbs_loss: 6.1426 - EndIdxProbs_loss: 6.3665 - StartIdxProbs_categorical_accuracy: 0.0957 - EndIdxProbs_categorical_accuracy: 0.0087 - val_loss: 13.8776 - val_StartIdxProbs_loss: 6.9287 - val_EndIdxProbs_loss: 6.7762 - val_StartIdxProbs_categorical_accuracy: 0.0000e+00 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 1/1     Batch 162/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 2s 15ms/step - loss: 13.2943 - StartIdxProbs_loss: 6.4301 - EndIdxProbs_loss: 6.6915 - StartIdxProbs_categorical_accuracy: 0.0696 - EndIdxProbs_categorical_accuracy: 0.0000e+00 - val_loss: 12.0633 - val_StartIdxProbs_loss: 5.8145 - val_EndIdxProbs_loss: 6.0762 - val_StartIdxProbs_categorical_accuracy: 0.1538 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 1/1     Batch 163/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 2s 15ms/step - loss: 13.2917 - StartIdxProbs_loss: 6.5392 - EndIdxProbs_loss: 6.5800 - StartIdxProbs_categorical_accuracy: 0.0522 - EndIdxProbs_categorical_accuracy: 0.0000e+00 - val_loss: 13.4435 - val_StartIdxProbs_loss: 6.6259 - val_EndIdxProbs_loss: 6.6452 - val_StartIdxProbs_categorical_accuracy: 0.0000e+00 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 1/1     Batch 164/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 2s 15ms/step - loss: 13.8853 - StartIdxProbs_loss: 6.8450 - EndIdxProbs_loss: 6.8679 - StartIdxProbs_categorical_accuracy: 0.0087 - EndIdxProbs_categorical_accuracy: 0.0000e+00 - val_loss: 16.1660 - val_StartIdxProbs_loss: 7.8715 - val_EndIdxProbs_loss: 8.1223 - val_StartIdxProbs_categorical_accuracy: 0.0000e+00 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 1/1     Batch 165/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 2s 16ms/step - loss: 13.2203 - StartIdxProbs_loss: 6.4648 - EndIdxProbs_loss: 6.5832 - StartIdxProbs_categorical_accuracy: 0.0348 - EndIdxProbs_categorical_accuracy: 0.0087 - val_loss: 14.0180 - val_StartIdxProbs_loss: 6.7169 - val_EndIdxProbs_loss: 7.1290 - val_StartIdxProbs_categorical_accuracy: 0.0000e+00 - val_EndIdxProbs_categorical_accuracy: 0.0769\n",
      "\n",
      "Epoch 1/1     Batch 166/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 2s 15ms/step - loss: 13.0793 - StartIdxProbs_loss: 6.4171 - EndIdxProbs_loss: 6.4901 - StartIdxProbs_categorical_accuracy: 0.0174 - EndIdxProbs_categorical_accuracy: 0.0087 - val_loss: 12.6396 - val_StartIdxProbs_loss: 5.9252 - val_EndIdxProbs_loss: 6.5425 - val_StartIdxProbs_categorical_accuracy: 0.1538 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 1/1     Batch 167/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 2s 15ms/step - loss: 13.2978 - StartIdxProbs_loss: 6.4553 - EndIdxProbs_loss: 6.6705 - StartIdxProbs_categorical_accuracy: 0.0783 - EndIdxProbs_categorical_accuracy: 0.0000e+00 - val_loss: 13.8798 - val_StartIdxProbs_loss: 6.8560 - val_EndIdxProbs_loss: 6.8519 - val_StartIdxProbs_categorical_accuracy: 0.0000e+00 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 1/1     Batch 168/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 2s 15ms/step - loss: 13.2944 - StartIdxProbs_loss: 6.5017 - EndIdxProbs_loss: 6.6207 - StartIdxProbs_categorical_accuracy: 0.0348 - EndIdxProbs_categorical_accuracy: 0.0000e+00 - val_loss: 13.2670 - val_StartIdxProbs_loss: 6.5147 - val_EndIdxProbs_loss: 6.5806 - val_StartIdxProbs_categorical_accuracy: 0.0769 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 1/1     Batch 169/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 2s 16ms/step - loss: 13.2365 - StartIdxProbs_loss: 6.5071 - EndIdxProbs_loss: 6.5576 - StartIdxProbs_categorical_accuracy: 0.0348 - EndIdxProbs_categorical_accuracy: 0.0000e+00 - val_loss: 12.7223 - val_StartIdxProbs_loss: 6.2385 - val_EndIdxProbs_loss: 6.3121 - val_StartIdxProbs_categorical_accuracy: 0.0769 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 1/1     Batch 170/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 2s 16ms/step - loss: 13.4254 - StartIdxProbs_loss: 6.6267 - EndIdxProbs_loss: 6.6271 - StartIdxProbs_categorical_accuracy: 0.0174 - EndIdxProbs_categorical_accuracy: 0.0435 - val_loss: 12.8705 - val_StartIdxProbs_loss: 5.9925 - val_EndIdxProbs_loss: 6.7065 - val_StartIdxProbs_categorical_accuracy: 0.0769 - val_EndIdxProbs_categorical_accuracy: 0.0769\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/1     Batch 171/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 2s 16ms/step - loss: 13.4702 - StartIdxProbs_loss: 6.6622 - EndIdxProbs_loss: 6.6364 - StartIdxProbs_categorical_accuracy: 0.0087 - EndIdxProbs_categorical_accuracy: 0.0000e+00 - val_loss: 11.7751 - val_StartIdxProbs_loss: 5.5652 - val_EndIdxProbs_loss: 6.0385 - val_StartIdxProbs_categorical_accuracy: 0.2308 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 1/1     Batch 172/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 2s 15ms/step - loss: 13.2495 - StartIdxProbs_loss: 6.5475 - EndIdxProbs_loss: 6.5306 - StartIdxProbs_categorical_accuracy: 0.0174 - EndIdxProbs_categorical_accuracy: 0.0000e+00 - val_loss: 14.2343 - val_StartIdxProbs_loss: 7.0189 - val_EndIdxProbs_loss: 7.0442 - val_StartIdxProbs_categorical_accuracy: 0.0000e+00 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 1/1     Batch 173/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 2s 15ms/step - loss: 13.0830 - StartIdxProbs_loss: 6.4069 - EndIdxProbs_loss: 6.5048 - StartIdxProbs_categorical_accuracy: 0.0000e+00 - EndIdxProbs_categorical_accuracy: 0.0000e+00 - val_loss: 13.3998 - val_StartIdxProbs_loss: 6.5987 - val_EndIdxProbs_loss: 6.6300 - val_StartIdxProbs_categorical_accuracy: 0.0000e+00 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 1/1     Batch 174/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 2s 15ms/step - loss: 13.1126 - StartIdxProbs_loss: 6.4802 - EndIdxProbs_loss: 6.4612 - StartIdxProbs_categorical_accuracy: 0.0087 - EndIdxProbs_categorical_accuracy: 0.0000e+00 - val_loss: 13.1736 - val_StartIdxProbs_loss: 6.4342 - val_EndIdxProbs_loss: 6.5683 - val_StartIdxProbs_categorical_accuracy: 0.0000e+00 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 1/1     Batch 175/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 2s 15ms/step - loss: 13.6348 - StartIdxProbs_loss: 6.6719 - EndIdxProbs_loss: 6.7919 - StartIdxProbs_categorical_accuracy: 0.0348 - EndIdxProbs_categorical_accuracy: 0.0174 - val_loss: 13.3649 - val_StartIdxProbs_loss: 6.5573 - val_EndIdxProbs_loss: 6.6367 - val_StartIdxProbs_categorical_accuracy: 0.0000e+00 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 1/1     Batch 176/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 2s 15ms/step - loss: 13.7370 - StartIdxProbs_loss: 6.6861 - EndIdxProbs_loss: 6.8800 - StartIdxProbs_categorical_accuracy: 0.0696 - EndIdxProbs_categorical_accuracy: 0.0261 - val_loss: 13.1215 - val_StartIdxProbs_loss: 6.4368 - val_EndIdxProbs_loss: 6.5139 - val_StartIdxProbs_categorical_accuracy: 0.0769 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 1/1     Batch 177/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 2s 15ms/step - loss: 13.8475 - StartIdxProbs_loss: 6.7669 - EndIdxProbs_loss: 6.9098 - StartIdxProbs_categorical_accuracy: 0.0261 - EndIdxProbs_categorical_accuracy: 0.0000e+00 - val_loss: 13.3341 - val_StartIdxProbs_loss: 6.6210 - val_EndIdxProbs_loss: 6.5425 - val_StartIdxProbs_categorical_accuracy: 0.0000e+00 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 1/1     Batch 178/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 2s 15ms/step - loss: 13.6102 - StartIdxProbs_loss: 6.6892 - EndIdxProbs_loss: 6.7503 - StartIdxProbs_categorical_accuracy: 0.0174 - EndIdxProbs_categorical_accuracy: 0.0087 - val_loss: 13.8846 - val_StartIdxProbs_loss: 6.8558 - val_EndIdxProbs_loss: 6.8583 - val_StartIdxProbs_categorical_accuracy: 0.0000e+00 - val_EndIdxProbs_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 1/1     Batch 179/678\n",
      "Train on 115 samples, validate on 13 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[115,854,25] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu\n\t [[Node: training/Adam/gradients/ContextBiGRU/ReverseV2_2_grad/ReverseV2 = ReverseV2[T=DT_FLOAT, Tidx=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](training/Adam/gradients/ContextBiGRU/concat_grad/Slice_1, episodic_memory_module_1/soft_attn_gru_2_2/TensorArrayUnstack/strided_slice/stack_1)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-022794348f21>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     14\u001b[0m         history = DMN_model.fit(x=[padded_contexts, padded_sent_end_indices, padded_questions],\n\u001b[0;32m     15\u001b[0m                                 \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my_answer_start\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_answer_end\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m                                 batch_size=batch_size, validation_split=0.1)\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0mhistory_objects\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3_\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1040\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1042\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1043\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1044\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\Anaconda3_\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3_\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2659\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2660\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2661\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2662\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2663\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3_\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2629\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2630\u001b[0m                                 session)\n\u001b[1;32m-> 2631\u001b[1;33m         \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2632\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2633\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3_\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1452\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1453\u001b[0m           return tf_session.TF_DeprecatedSessionRunCallable(\n\u001b[1;32m-> 1454\u001b[1;33m               self._session._session, self._handle, args, status, None)\n\u001b[0m\u001b[0;32m   1455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1456\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__del__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3_\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[0;32m    517\u001b[0m             \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    518\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 519\u001b[1;33m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[0;32m    520\u001b[0m     \u001b[1;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    521\u001b[0m     \u001b[1;31m# as there is a reference to status from this from the traceback due to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[115,854,25] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu\n\t [[Node: training/Adam/gradients/ContextBiGRU/ReverseV2_2_grad/ReverseV2 = ReverseV2[T=DT_FLOAT, Tidx=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](training/Adam/gradients/ContextBiGRU/concat_grad/Slice_1, episodic_memory_module_1/soft_attn_gru_2_2/TensorArrayUnstack/strided_slice/stack_1)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n"
     ]
    }
   ],
   "source": [
    "history_objects = []\n",
    "batch_iteration = 0\n",
    "for epoch in range(num_of_epochs):\n",
    "    for batch_idx in range(num_of_batches):\n",
    "        print(\"\\nEpoch %d/%d     Batch %d/%d\" % (epoch+1, num_of_epochs, batch_iteration+1, num_of_batches))\n",
    "        start, end = (batch_idx*batch_size, (batch_idx+1)*batch_size)\n",
    "    \n",
    "        y_answer_start, y_answer_end = (get_answer_span(answer_start[start:end], answer_end[start:end]))\n",
    "        padded_contexts = get_padded_inputs(tokenized_contexts[start:end], string_type=\"context\")\n",
    "        padded_questions = get_padded_inputs(tokenized_questions[start:end], string_type=\"question\")\n",
    "        padded_sent_end_indices = pad_sequences(sent_end_indices[start:end], max_sent_num,\n",
    "                                                                    padding=\"post\", dtype=\"int32\")\n",
    "\n",
    "        history = DMN_model.fit(x=[padded_contexts, padded_sent_end_indices, padded_questions],\n",
    "                                y=[y_answer_start, y_answer_end],\n",
    "                                batch_size=batch_size, validation_split=0.1)\n",
    "        \n",
    "        history_objects.append(history)\n",
    "        batch_iteration+=1\n",
    "        del start, end, y_answer_start, y_answer_end, padded_contexts, padded_questions, padded_sent_end_indices\n",
    "\n",
    "    batch_iteration = 0 # Reset batch iteration counter for each new epoch\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DMN_model.save('DMN_model.h5')  # creates a HDF5 file 'my_model.h5'\n",
    "#del model  # deletes the existing model\n",
    "\n",
    "# returns a compiled model identical to the previous one\n",
    "DMN_model_loaded = load_model('DMN_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Notes before testing:\n",
    "    Have a careful look at the 'get_facts' method to get an idea of how training and testing\n",
    "    are different. We must do 3 things:\n",
    "    1. Assign value to test_send_end_indices\n",
    "    2. Set 'training' to False\n",
    "    3. Set 'batch_size' parameter in .predict() to be the number of smaples we are testing on. \n",
    "    4. Only do 1 test. Otherwise modify 'get_facts'\"\"\"\n",
    "\n",
    "test_batch_size=20\n",
    "\n",
    "test_contexts = None\n",
    "\n",
    "context_inputs = None\n",
    "indices_inputs = None\n",
    "question_inputs = None\n",
    "\n",
    "test_outputs = DMN_model.predict([context_inputs, indices_inputs, question_inputs], batch_size=test_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Test of the context model\n",
    "\"\"\"\n",
    "context_model = Model(inputs=[context_input, sent_end_idx_input], outputs=facts_mask)\n",
    "\n",
    "#Setting up test variables\n",
    "padded_contexts = get_padded_inputs(tokenized_contexts[0:batch_size], string_type=\"context\")\n",
    "padded_sent_end_indices = pad_sequences(sent_end_indices[0:batch_size], max_sent_num, padding=\"post\", dtype=\"int32\")\n",
    "y_test = tf.zeros((batch_size, max_sent_num, word_vector_size), dtype=tf.float32)\n",
    "\n",
    "context_model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=learning_rate),\n",
    "                      metrics=['accuracy', \"categorical_accuracy\"])\n",
    "history = context_model.fit(x=[padded_contexts, padded_sent_end_indices], y=y_test,\n",
    "                        batch_size=None, validation_split=0.1, steps_per_epoch=1, validation_steps=1)\n",
    "predictions = context_model.predict([padded_contexts, padded_sent_end_indices], batch_size=batch_size)\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
